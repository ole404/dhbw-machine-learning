{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Warum ist es wichtig Elon Musk Tweets zu generieren?\n",
    "Elon Musk ist seit 2020 der reichste Mann der Welt. Zusätzlich ist er eine der einflussreichsten Personen auf der Plattform und baut diesen Einfluss damit aus, dass der seit 2022 der größte Anteilseigner der Plattform ist. Bei den Theman Unternehmensanteile, Elon Musk und Twitter wird es auch abseits von Elon Musks persönlicher Finanzlage interessant. Musk ist bekannt dafür, in den letzten Jahren mit seinen Tweets Aktienkurse beeinflusst zu haben. Er hat beispielsweise 2018 getwittert, dass er Tesla bei einem Aktienpreis von $420 wieder zu einem privaten, nicht gehandelten, Unternehmen machen würde. Dadurch stieg der Preis für die Aktie in den folgenden Tagen signifikant an [Vgl. SEC 2018](https://www.sec.gov/news/press-release/2018-219)\n",
    "Wer finanzielle Interessen hat, könnte sich davon ausgehen damit beschäftigen, ein System zu entwickeln, das anhand von Elon Musks Meinung Aktien und Optionen kauft.\n",
    "Wer finanzielle Interessen hat, sollte sich aber vielleicht auch nicht mit Elon Musks Tweets beschäftigen und denken, dass er anhand dessen der nächste Warren Buffet wird, sondern arbeiten. Viel interessanter wäre es doch eigene Tweets zu generieren. Einen Wert für die Gesellschaft hat das nicht. Damit lässt sich dennoch eine interessante Beobachtung machen. Textinhalte bei Twitter sind auf 240 Zeichen begrenzt. Komplexe Zusammenhänge mit verschiedenen Aussagen in einzelnen Tweets sind dadurch nur begrenzt möglich. Die meisten Sprachmodelle haben auch genau damit ein Problem, lange zusammenhängende Texte zu generieren in denen verschiedene Aussagen koherent sind.\n",
    "Die Idee Tweets mit einem Sprachmodell zu generieren ist also eigentlich sehr naheliegend und dies auch nicht der erste Ansatz. Diese fokussieren sich aber alle auf Twitter im Allgemeinen und nicht spezifisch auf das Profil eines Nutzers oder eine Nutzerin. Das Interessante an einem einzelnen Profil, ist dass die Sprache und die Gedanken eines einzelnen Menschen nachgestellt werden und nicht einer ganzen Gruppe. Genau ein Mensch nicht wie alle Menschen auf Twitter spricht, soll das Model auch nicht lernen wie alle Menschen zu sprechen, sondern eben nur wie ein Mensch zu sprechen.\n",
    "### Elon Musks Twitter Profil\n",
    "![Elon Musks Twitter Profil](elonmusk_twitter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ole\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ole\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras_tuner.engine.hyperparameters\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import DefaultDataCollator, pipeline, AutoTokenizer, AutoModelForCausalLM, TFGPT2LMHeadModel, AdamWeightDecay, TFAutoModelForCausalLM\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prüfen der Hardwarebeschleunigung\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.test.gpu_device_name()\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zur Datenbeschaffung lässt sich theoretisch die API von Twitter nutzen, allerdings gibt es einen [Kaggle-Datensatz](https://www.kaggle.com/datasets/ayhmrba/elon-musk-tweets-2010-2021), in dem die Tweets der API bereits aufbereitet sind. Der Datensatz enthält zweets von 2010 bis 2022 in einzelnen Dateien. Alle dateien werden eingelesen und in einen DataFrame zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_from_years = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in os.listdir('musktweets'):\n",
    "    year = i.rstrip('.csv')\n",
    "    if i == '2021.csv' or i == '2022.csv':\n",
    "        tweets_from_years[year] = pd.read_csv('musktweets/'+i)\n",
    "    else:\n",
    "        tweets_from_years[year] = pd.read_csv('musktweets/'+i, index_col='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Tabellen ab 2020 haben ein leicht verändertes Schema und müssen an die anderen angepasst werden. Außerdem werden nur bestimmte Felder zu weiteren Arbeit genutzt und die relativ häufigen Duplikate im Datensatz entfernt. Insgesamt sind das nur kosmetische Anpassungen, zur leichteren Arbeit mit dem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'conversation_id', 'created_at', 'date', 'timezone', 'place',\n",
      "       'tweet', 'language', 'hashtags', 'cashtags', 'user_id', 'user_id_str',\n",
      "       'username', 'name', 'day', 'hour', 'link', 'urls', 'photos', 'video',\n",
      "       'thumbnail', 'retweet', 'nlikes', 'nreplies', 'nretweets', 'quote_url',\n",
      "       'search', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n",
      "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
      "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
      "       'urls', 'photos', 'replies_count', 'retweets_count', 'nlikes',\n",
      "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
      "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n",
      "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
      "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
      "       'urls', 'photos', 'replies_count', 'retweets_count', 'nlikes',\n",
      "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
      "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for year in tweets_from_years:\n",
    "    if year == '2022' or year == '2021' or year == '2020':\n",
    "        tweets_from_years[year].rename(columns={'likes_count':'nlikes'}, inplace=True)\n",
    "        print(tweets_from_years[year].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1476662222617251846</td>\n",
       "      <td>1476620230692679680</td>\n",
       "      <td>2021-12-31 01:11:23 Arabian Standard Time</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>01:11:23</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'roshanpateI', 'name': 'Rosha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1476656306610216960</td>\n",
       "      <td>1476644467578859528</td>\n",
       "      <td>2021-12-31 00:47:53 Arabian Standard Time</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>00:47:53</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'tesla_raj', 'name': 'Tesla R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1476651519986614281</td>\n",
       "      <td>1476252898115964928</td>\n",
       "      <td>2021-12-31 00:28:51 Arabian Standard Time</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>00:28:51</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'CSmithson80', 'name': 'Chris...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1476619907076923398</td>\n",
       "      <td>1476252898115964928</td>\n",
       "      <td>2021-12-30 22:23:14 Arabian Standard Time</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>22:23:14</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1476618021024190474</td>\n",
       "      <td>1476252898115964928</td>\n",
       "      <td>2021-12-30 22:15:45 Arabian Standard Time</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>22:15:45</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'mims', 'name': 'Christopher ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>1345384139969552389</td>\n",
       "      <td>1345382294966571008</td>\n",
       "      <td>2021-01-02 18:59:09 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>18:59:09</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'flcnhvy', 'name': 'Viv ✶', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>1345382294966571008</td>\n",
       "      <td>1345382294966571008</td>\n",
       "      <td>2021-01-02 18:51:49 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>18:51:49</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>1345344958710992897</td>\n",
       "      <td>1345334831719337984</td>\n",
       "      <td>2021-01-02 16:23:28 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>16:23:28</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'newscientist', 'name': 'New ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>1345208391958888448</td>\n",
       "      <td>1344675033231237120</td>\n",
       "      <td>2021-01-02 07:20:48 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>07:20:48</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'comma_ai', 'name': 'comma', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>1344810193952014336</td>\n",
       "      <td>1344518758707113986</td>\n",
       "      <td>2021-01-01 04:58:30 Arabian Standard Time</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>04:58:30</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'PPathole', 'name': 'Pranay P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3115 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id      conversation_id  \\\n",
       "0     1476662222617251846  1476620230692679680   \n",
       "1     1476656306610216960  1476644467578859528   \n",
       "2     1476651519986614281  1476252898115964928   \n",
       "3     1476619907076923398  1476252898115964928   \n",
       "4     1476618021024190474  1476252898115964928   \n",
       "...                   ...                  ...   \n",
       "3110  1345384139969552389  1345382294966571008   \n",
       "3111  1345382294966571008  1345382294966571008   \n",
       "3112  1345344958710992897  1345334831719337984   \n",
       "3113  1345208391958888448  1344675033231237120   \n",
       "3114  1344810193952014336  1344518758707113986   \n",
       "\n",
       "                                     created_at        date      time  \\\n",
       "0     2021-12-31 01:11:23 Arabian Standard Time  2021-12-31  01:11:23   \n",
       "1     2021-12-31 00:47:53 Arabian Standard Time  2021-12-31  00:47:53   \n",
       "2     2021-12-31 00:28:51 Arabian Standard Time  2021-12-31  00:28:51   \n",
       "3     2021-12-30 22:23:14 Arabian Standard Time  2021-12-30  22:23:14   \n",
       "4     2021-12-30 22:15:45 Arabian Standard Time  2021-12-30  22:15:45   \n",
       "...                                         ...         ...       ...   \n",
       "3110  2021-01-02 18:59:09 Arabian Standard Time  2021-01-02  18:59:09   \n",
       "3111  2021-01-02 18:51:49 Arabian Standard Time  2021-01-02  18:51:49   \n",
       "3112  2021-01-02 16:23:28 Arabian Standard Time  2021-01-02  16:23:28   \n",
       "3113  2021-01-02 07:20:48 Arabian Standard Time  2021-01-02  07:20:48   \n",
       "3114  2021-01-01 04:58:30 Arabian Standard Time  2021-01-01  04:58:30   \n",
       "\n",
       "      timezone   user_id  username       name  place  ... geo source  \\\n",
       "0          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "1          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "2          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "4          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "...        ...       ...       ...        ...    ...  ...  ..    ...   \n",
       "3110       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3111       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3112       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3113       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3114       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "\n",
       "     user_rt_id user_rt retweet_id  \\\n",
       "0           NaN     NaN        NaN   \n",
       "1           NaN     NaN        NaN   \n",
       "2           NaN     NaN        NaN   \n",
       "3           NaN     NaN        NaN   \n",
       "4           NaN     NaN        NaN   \n",
       "...         ...     ...        ...   \n",
       "3110        NaN     NaN        NaN   \n",
       "3111        NaN     NaN        NaN   \n",
       "3112        NaN     NaN        NaN   \n",
       "3113        NaN     NaN        NaN   \n",
       "3114        NaN     NaN        NaN   \n",
       "\n",
       "                                               reply_to  retweet_date  \\\n",
       "0     [{'screen_name': 'roshanpateI', 'name': 'Rosha...           NaN   \n",
       "1     [{'screen_name': 'tesla_raj', 'name': 'Tesla R...           NaN   \n",
       "2     [{'screen_name': 'CSmithson80', 'name': 'Chris...           NaN   \n",
       "3     [{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...           NaN   \n",
       "4     [{'screen_name': 'mims', 'name': 'Christopher ...           NaN   \n",
       "...                                                 ...           ...   \n",
       "3110  [{'screen_name': 'flcnhvy', 'name': 'Viv ✶', '...           NaN   \n",
       "3111                                                 []           NaN   \n",
       "3112  [{'screen_name': 'newscientist', 'name': 'New ...           NaN   \n",
       "3113  [{'screen_name': 'comma_ai', 'name': 'comma', ...           NaN   \n",
       "3114  [{'screen_name': 'PPathole', 'name': 'Pranay P...           NaN   \n",
       "\n",
       "      translate trans_src trans_dest  \n",
       "0           NaN       NaN        NaN  \n",
       "1           NaN       NaN        NaN  \n",
       "2           NaN       NaN        NaN  \n",
       "3           NaN       NaN        NaN  \n",
       "4           NaN       NaN        NaN  \n",
       "...         ...       ...        ...  \n",
       "3110        NaN       NaN        NaN  \n",
       "3111        NaN       NaN        NaN  \n",
       "3112        NaN       NaN        NaN  \n",
       "3113        NaN       NaN        NaN  \n",
       "3114        NaN       NaN        NaN  \n",
       "\n",
       "[3115 rows x 36 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_years['2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>photos</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4652</td>\n",
       "      <td>2010-06-04 18:31:57</td>\n",
       "      <td>https://twitter.com/elonmusk/status/15434727182</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-28 22:27:08</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1521536376...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TheOnion So true :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2011-12-27 23:38:55</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1518093150...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you ever wanted to know the *real* truth ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>2011-12-26 16:29:50</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1513389393...</td>\n",
       "      <td>['https://pbs.twimg.com/media/Ahmp9qtCAAAYPDX....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walked around a neighborhood recently rebuilt ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>2011-12-26 16:23:04</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1513372374...</td>\n",
       "      <td>['https://pbs.twimg.com/media/AhmoamaCQAANvSt....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was Xmas, so we brought presents for the ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34873</th>\n",
       "      <td>1023</td>\n",
       "      <td>473530</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477775713...</td>\n",
       "      <td>['https://pbs.twimg.com/media/FIIdLYoXoAEd2j_....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/LA9hPzVlGx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34874</th>\n",
       "      <td>1024</td>\n",
       "      <td>320201</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477706142...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let’s make the roaring 20’s happen!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34875</th>\n",
       "      <td>1025</td>\n",
       "      <td>66405</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477700424...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great work by Tesla team worldwide!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34876</th>\n",
       "      <td>1026</td>\n",
       "      <td>45704</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477096955...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BLKMDL3 @Tesla 🔥</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34877</th>\n",
       "      <td>1027</td>\n",
       "      <td>4127</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477080438...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'MiFSDBetaTester', 'name': 'R...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MiFSDBetaTester @WholeMarsBlog 🤣</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34878 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  nlikes                 date  \\\n",
       "0          0    4652  2010-06-04 18:31:57   \n",
       "1          0      12  2011-12-28 22:27:08   \n",
       "2          1      39  2011-12-27 23:38:55   \n",
       "3          2     155  2011-12-26 16:29:50   \n",
       "4          3     158  2011-12-26 16:23:04   \n",
       "...      ...     ...                  ...   \n",
       "34873   1023  473530           2022-01-03   \n",
       "34874   1024  320201           2022-01-02   \n",
       "34875   1025   66405           2022-01-02   \n",
       "34876   1026   45704           2022-01-01   \n",
       "34877   1027    4127           2022-01-01   \n",
       "\n",
       "                                                    link  \\\n",
       "0        https://twitter.com/elonmusk/status/15434727182   \n",
       "1      https://twitter.com/elonmusk/status/1521536376...   \n",
       "2      https://twitter.com/elonmusk/status/1518093150...   \n",
       "3      https://twitter.com/elonmusk/status/1513389393...   \n",
       "4      https://twitter.com/elonmusk/status/1513372374...   \n",
       "...                                                  ...   \n",
       "34873  https://twitter.com/elonmusk/status/1477775713...   \n",
       "34874  https://twitter.com/elonmusk/status/1477706142...   \n",
       "34875  https://twitter.com/elonmusk/status/1477700424...   \n",
       "34876  https://twitter.com/elonmusk/status/1477096955...   \n",
       "34877  https://twitter.com/elonmusk/status/1477080438...   \n",
       "\n",
       "                                                  photos  \\\n",
       "0                                                     []   \n",
       "1                                                     []   \n",
       "2                                                     []   \n",
       "3      ['https://pbs.twimg.com/media/Ahmp9qtCAAAYPDX....   \n",
       "4      ['https://pbs.twimg.com/media/AhmoamaCQAANvSt....   \n",
       "...                                                  ...   \n",
       "34873  ['https://pbs.twimg.com/media/FIIdLYoXoAEd2j_....   \n",
       "34874                                                 []   \n",
       "34875                                                 []   \n",
       "34876                                                 []   \n",
       "34877                                                 []   \n",
       "\n",
       "                                                reply_to  retweet  source  \\\n",
       "0                                                     []    False     NaN   \n",
       "1                                                     []    False     NaN   \n",
       "2                                                     []    False     NaN   \n",
       "3                                                     []    False     NaN   \n",
       "4                                                     []    False     NaN   \n",
       "...                                                  ...      ...     ...   \n",
       "34873                                                 []    False     NaN   \n",
       "34874                                                 []    False     NaN   \n",
       "34875                                                 []    False     NaN   \n",
       "34876  [{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...    False     NaN   \n",
       "34877  [{'screen_name': 'MiFSDBetaTester', 'name': 'R...    False     NaN   \n",
       "\n",
       "                                                   tweet  video  \n",
       "0      Please ignore prior tweets, as that was someon...      0  \n",
       "1                                   @TheOnion So true :)      0  \n",
       "2      If you ever wanted to know the *real* truth ab...      0  \n",
       "3      Walked around a neighborhood recently rebuilt ...      1  \n",
       "4      It was Xmas, so we brought presents for the ki...      1  \n",
       "...                                                  ...    ...  \n",
       "34873                            https://t.co/LA9hPzVlGx      1  \n",
       "34874                Let’s make the roaring 20’s happen!      0  \n",
       "34875                Great work by Tesla team worldwide!      0  \n",
       "34876                                  @BLKMDL3 @Tesla 🔥      0  \n",
       "34877                  @MiFSDBetaTester @WholeMarsBlog 🤣      0  \n",
       "\n",
       "[34878 rows x 10 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year in tweets_from_years:\n",
    "    tweets_from_years[year] = tweets_from_years[year][['nlikes','date', 'link','photos','reply_to','retweet','source','tweet','video']]\n",
    "tweets_from_all_years = pd.concat([tweets_from_years[year] for year in tweets_from_years.keys()])\n",
    "tweets_from_all_years = tweets_from_all_years.reset_index()\n",
    "tweets_from_all_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ein paar Typconvertierungen\n",
    "tweets_from_all_years['date'] = tweets_from_all_years['date'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_from_all_years = tweets_from_all_years.drop_duplicates(subset='tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den 15219 Tweets gibt es 10329 Antworten auf Tweets von anderen NutzerInnen. In der Wortwahl sind Antworten aber anders als eigenständige Tweets, weil Menschen ihre Sprache unterbewusst an die Sprache der anderen Menschen anpasst. Ohne den Kontext des ursprünglichen Tweet, ergibt ein Tweet außerdem inhaltlich auch nur wenig Sinn. Die automatische Generierung von Antworten wäre aber ein interessantes separates Projekt. In diesem Projekt werden aber nur eigenständige Tweets generiert, weshalb Tweets, die Antworten auf andere Tweets sind entfernt werden. In diesem Punkt unterscheidet sich das Projekt auch von einem anderen Projekt mit diesem Datensatz, in dem Tweets generiert wurden. In diesem Projekt waren auch antworten enthalten, weshalb primär fiktive Antworten auf andere Nutzer generiert werden. Es bleiben also 4890 Tweets für das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_from_all_years = tweets_from_all_years[(tweets_from_all_years['reply_to']=='[]') & (tweets_from_all_years['retweet']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_all_years[(tweets_from_all_years['retweet']!=False)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Für das Training werden außerdem Links durch einen Link Tag 'link' ersetzt, weil mit einem Modell natürlich keine echten Links generiert werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url_re = re.compile(r\"https?:\\/\\/\\S*\")\n",
    "tweets_from_all_years['tweet']=tweets_from_all_years.apply(lambda x: url_re.sub('<link>',x['tweet'] if x['video'] == 0 else url_re.sub('<image>',x['tweet'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>photos</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>522</td>\n",
       "      <td>144</td>\n",
       "      <td>2016-04-30 01:14:50</td>\n",
       "      <td>https://twitter.com/elonmusk/status/7262182181...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@phillipcjackson turns out it doesn't need sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>1143</td>\n",
       "      <td>114300</td>\n",
       "      <td>2019-07-27 18:15:32</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1155179932...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ability to stream YouTube &amp;amp; Netflix when c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>1753</td>\n",
       "      <td>18065</td>\n",
       "      <td>2019-05-12 01:54:33</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1127391581...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Much will likely go wrong on 1st mission. Also...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>1496</td>\n",
       "      <td>22488</td>\n",
       "      <td>2018-06-10 06:33:43</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1005699514...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is why I’m not impressed when reporters w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>72</td>\n",
       "      <td>509</td>\n",
       "      <td>2014-08-03 19:11:50</td>\n",
       "      <td>https://twitter.com/elonmusk/status/4960105723...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While on the subject of AI risk, Our Final Inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>173</td>\n",
       "      <td>21</td>\n",
       "      <td>2012-04-30 20:10:22</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1970553142...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T minus five minutes to flame</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33939</th>\n",
       "      <td>89</td>\n",
       "      <td>205929</td>\n",
       "      <td>2022-02-23 00:00:00</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1496252264...</td>\n",
       "      <td>['https://pbs.twimg.com/media/FMPBgHWWUAoro-w....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;image&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21311</th>\n",
       "      <td>2293</td>\n",
       "      <td>102318</td>\n",
       "      <td>2020-04-30 17:54:59</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1255918585...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classifying all deaths as corona even if coron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31340</th>\n",
       "      <td>605</td>\n",
       "      <td>48501</td>\n",
       "      <td>2021-11-03 00:00:00</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1455980193...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And Mars  &lt;link&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33332</th>\n",
       "      <td>2597</td>\n",
       "      <td>99495</td>\n",
       "      <td>2021-03-12 00:00:00</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1370449655...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Both do mining &amp;amp; use blocks &amp;amp; chains</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  nlikes                date  \\\n",
       "3776     522     144 2016-04-30 01:14:50   \n",
       "11849   1143  114300 2019-07-27 18:15:32   \n",
       "12459   1753   18065 2019-05-12 01:54:33   \n",
       "9917    1496   22488 2018-06-10 06:33:43   \n",
       "1150      72     509 2014-08-03 19:11:50   \n",
       "201      173      21 2012-04-30 20:10:22   \n",
       "33939     89  205929 2022-02-23 00:00:00   \n",
       "21311   2293  102318 2020-04-30 17:54:59   \n",
       "31340    605   48501 2021-11-03 00:00:00   \n",
       "33332   2597   99495 2021-03-12 00:00:00   \n",
       "\n",
       "                                                    link  \\\n",
       "3776   https://twitter.com/elonmusk/status/7262182181...   \n",
       "11849  https://twitter.com/elonmusk/status/1155179932...   \n",
       "12459  https://twitter.com/elonmusk/status/1127391581...   \n",
       "9917   https://twitter.com/elonmusk/status/1005699514...   \n",
       "1150   https://twitter.com/elonmusk/status/4960105723...   \n",
       "201    https://twitter.com/elonmusk/status/1970553142...   \n",
       "33939  https://twitter.com/elonmusk/status/1496252264...   \n",
       "21311  https://twitter.com/elonmusk/status/1255918585...   \n",
       "31340  https://twitter.com/elonmusk/status/1455980193...   \n",
       "33332  https://twitter.com/elonmusk/status/1370449655...   \n",
       "\n",
       "                                                  photos reply_to  retweet  \\\n",
       "3776                                                  []       []    False   \n",
       "11849                                                 []       []    False   \n",
       "12459                                                 []       []    False   \n",
       "9917                                                  []       []    False   \n",
       "1150                                                  []       []    False   \n",
       "201                                                   []       []    False   \n",
       "33939  ['https://pbs.twimg.com/media/FMPBgHWWUAoro-w....       []    False   \n",
       "21311                                                 []       []    False   \n",
       "31340                                                 []       []    False   \n",
       "33332                                                 []       []    False   \n",
       "\n",
       "       source                                              tweet  video  \n",
       "3776      NaN  @phillipcjackson turns out it doesn't need sec...      0  \n",
       "11849     NaN  Ability to stream YouTube &amp; Netflix when c...      0  \n",
       "12459     NaN  Much will likely go wrong on 1st mission. Also...      0  \n",
       "9917      NaN  This is why I’m not impressed when reporters w...      0  \n",
       "1150      NaN  While on the subject of AI risk, Our Final Inv...      0  \n",
       "201       NaN                      T minus five minutes to flame      0  \n",
       "33939     NaN                                            <image>      1  \n",
       "21311     NaN  Classifying all deaths as corona even if coron...      0  \n",
       "31340     NaN                                   And Mars  <link>      0  \n",
       "33332     NaN       Both do mining &amp; use blocks &amp; chains      0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_all_years.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bevor Text generiert wird, ist es interessant sich einmal anzusehen, wie der Datensatz aufgebaut ist. Bei strukturierten und numerischen Daten gibt es dafür klare Möglichkeiten, die sich etabliert haben, wie etwa sich mit den Durchschnitten und Quantilen zu beschäftigen. Im Fall von Text ist das aber nicht direkt möglich und auch nicht wirklich nötig, weil es, wie später beschrieben nur wenig direkte Evaluierung gibt. Es ist aber wichtig ein Gefühl für den Datensatz zu erhalten um zu verstehen, ob die Generierungen gut oder schwach sind. Zuerst lässt sich die Herkunft der Daten bestimmen, aus welchem Jahr sie kommen. Wie zu erwarten ist hat Elon Musk mit voranschreitender Zeit mehr Tweets veröffentlicht. Der Datensatz reicht nur bis März 2022, weshalb es für das Jahr 2022 deutlich weniger Tweets sind, als im Juli 2022 zu erwarten wäre. 2019 war das aktivste Jahr von Elon Musk von Elon Musk. 2020 war er dann vermutlich damit beschäftigt sich über das erste Jahr zu freuen, in dem sein Unternehmen Tesla einen Gewinn abgeworfen hat und er twitterte entsprechend weniger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10), dpi=80)\n",
    "tweets_from_all_years.groupby(pd.Grouper(key = 'date',freq='Y')).size().plot(kind='bar')\n",
    "plt.xticks(range(13),['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020', '2021','2022'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zur Analyse des Textes der Tweets lässt sich ein tool wie Rake verwenden. Rake extrahiert die wichtigsten Keywords aus Texten. Dabei wird zuerst eine Stopwordliste angewendet, also eine Liste mit Wörtern die ignoriert werden sollen wie 'ist' oder 'das', weil sie sehr oft vorkommen aber nicht relevant für den Inhalt sind. Danach verwendet Rake verschiedene Methoden um die Wichtigkeit eines Wortes festzustellen, indem zum Beispiel die Co-Occurences mit anderen wichtigen Worten festgestellt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.0, '🖤🖤🖤🖤 🚘🚘🚘🚘 🖤🖤🖤🖤'),\n",
       " (9.0, '♥️♥️🇮🇸🇮🇸 ísland 🇮🇸🇮🇸♥️♥️'),\n",
       " (9.0, 'vigorously opposed subpoena'),\n",
       " (9.0, 'tcp packet walks'),\n",
       " (9.0, 'tallakt various forms'),\n",
       " (9.0, 'spinal cord transplant'),\n",
       " (9.0, 'spiked choker machined'),\n",
       " (9.0, 'some1gg transpiration cooling'),\n",
       " (9.0, 'siberian permafrost melting'),\n",
       " (9.0, 'shortseller enrichment commission')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_buzzwords = Rake(max_length=3)\n",
    "tweet_buzzwords.extract_keywords_from_sentences(tweets_from_all_years['tweet'].to_list())\n",
    "tweet_buzzwords.get_ranked_phrases_with_scores()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Ergebnisse der Keyword Extraktion sind allerdings nicht sehr aussagegräftig, wenn davon abgesehen wird, dass Musk scheinbar eine große Liebe für Island hat. Das ergibt aber auch durchaus Sinn, wenn bedacht wird, dass Rake eigentlich für größere Texte entwickelt wurde. [(Vgl. Rose 2010 et. al.)](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents) Eine deutlich interessantere Metrik ist in diesem Fall aber die Wordfrequenz, mit den angewendeten Stopwords. Also das einfache Zählen der Wörter und dann einem Entfernen aller Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kw_dist =  tweet_buzzwords.get_word_frequency_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## remove technical words and tokens\n",
    "del(kw_dist['amp'])\n",
    "del(kw_dist['link'])\n",
    "del(kw_dist['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n = 25\n",
    "kw_dist_top = {k:v for k,v in kw_dist.items() if v >= min(sorted(kw_dist.values(), reverse=True)[:n])}\n",
    "kw_dist_top_sorted = dict(sorted(kw_dist_top.items(), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10), dpi= 80)\n",
    "lables = []\n",
    "for i, w in enumerate(kw_dist_top_sorted):\n",
    "    plt.bar(x = i,height= kw_dist[w])\n",
    "plt.xticks(range(n),kw_dist_top_sorted.keys(), rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In gewisser Weise sind diese Ergebnisse dann doch überraschen, denn es ist nicht zu erwarten gewesen, dass Musk 'Tesla' und 'model' (von Model S oder Model 3, Modellbezeichungen der Tesla-Fahrzeuge) mehr als doppelt so oft vorkommen, wie die nächsten Top Wörter. Sonst wird sehr oft Launch, also SpaceX Launches erwähnt und allgemein viel über 'cars' getwittert, was aber zu erwarten ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Erstellung der Datensätze und Entwicklung des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zur Generierung von Text gibt es viele Möglichkeiten. Die klassische Methode sind Markov-Ketten, in denen immer das nächste Wort auf Basis des vorherigen Wortes vorhergesagt wird. Der moderne Ansatz sind auf neuronalen Netzen aufbauende Modelle. Einfache Perceptrons bieten aber nur wenige bis keine Möglichkeiten zusammenhängende Sätze zu verarbeiten. Stattdessen wurden Architekturen wie Recurrent Neural Networks entwickelt, in denen Neuronen auch mit Ausgaben folgender Neuronen gefüttert werden. Das LSTM speichert Eingaben vorheriger Eingaben und kann so mit sequentiellen Daten arbeiten. Der heutige Standard sind aber sogenannte Transformer. Ihre Grundlage ist der Attention-Mechanismus. Attention beruht auf Lookup-Tabellen, die im Netzwerk anlernbar sind. Beim Vorhersagen eines Elements in einer Sequenz kann also auch gelernt werden, welche Elemente davor und danach vorkommen. Das Training ist dafür sehr aufwändigt und benätigt einen sehr großen Korpus. Ein Modell, das mit einem solchen Korpus trainiert wurde ist GPT2. Der Korpus besteht aus den Texten von 8 Millionen Websites, auf die von der Internet-Plattform Reddit verlinkt wird. Weil die generierten Texte dadurch sehr gut Texte widerspiegeln, die im Internet zu finden sind, wird GPT-2 sehr oft für die Generierung von Texten, die Sprache im Intenet imitieren sollen genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Elon Musk is a ersatz social conservative. The internet does not represent any individual's political viewpoints. You might call him a fascist or a dictator, but he can't be taken into account by anyone. It is impossible to know if he\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"Elon Musk is a \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Modell ist aber die Sprache von Elon Musk nicht gut repräsentiert. Um das zu verbessern wird auf Transfer-Learning zurückgegriffen. Beim Transfer Learning wird statt ein neues Modell zu trainieren ein existierendes Modell wie GPT-2 mit den spezifischen Daten trainiert. Die Bibliothek `transformers` bietet dafür eine Reihe von existierienden Modellen, darunter auch GTP-2 an.\n",
    "Sprachemodelle können nicht mit den Rohen sprachdaten trainiert werden. Sie werden mit einer aneinanderreihung von Tokens, also numerischen Werten, die die einzelnen Wörter repräsentieren trainiert. GPT-2 bietet bereits einen passenden Tokenizer, der auf Texte mit Elon Musks Tweets angepasst werden muss. Weil das Modell immer ein Prompt braucht im Text zu generieren, wird ein `BOS_TOKEN` hinzugefügt, der als Prompt auch im Training vor jedem Tweet eingefügt wird. So lernt das Modell, dass jedem Prompt, ein Tweet von Elon Musk folgt. Es gibt auch einen End of Sequence Token, damit soll unter anderem gelernt werden, keine zu langen Texte zu generieren. In der Praxis funktioniert dies aber nur bedingt zuverlässig. Der `IMAGE_TOKEN` und der `LINK_TOKEN` sollen dafür sorgen, dass diese Teile des textes nicht aus anderne Tokens zusammengesetzt werden sondern immer am Stück vorhergesagt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<|elontext|>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "PAD_TOKEN = \"<|pad|>\"\n",
    "IMAGE_TOKEN = \"<image>\"\n",
    "LINK_TOKEN = \"<link>\"\n",
    "MAX_TOKENS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\",\n",
    "    bos_token=BOS_TOKEN,\n",
    "    eos_token=EOS_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    max_length=MAX_TOKENS,\n",
    "    is_split_into_words=True,\n",
    ")\n",
    "tokenizer.add_tokens([LINK_TOKEN, IMAGE_TOKEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Tokenizer werden auch gespeichert, damit sie später zur Weiterverwendung verfügbar sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained('./musktokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Neben GPT-2 wird außerdem noch das Modell 'distil-gpt2' genutzt. Das ist eine kleinere Version von 'GPT-2' und nutzt etwa die Hälfte der Neuronen bzw. Parameter. Beide Modelle sollen verglichen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\",\n",
    "                                          bos_token=BOS_TOKEN,\n",
    "                                          eos_token=EOS_TOKEN,\n",
    "                                          pad_token=PAD_TOKEN,\n",
    "                                          max_length=MAX_TOKENS,\n",
    "                                          is_split_into_words=True,\n",
    "                                          )\n",
    "distil_tokenizer.add_tokens([LINK_TOKEN, IMAGE_TOKEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um sicher zu gehen, dass mit korrekten Daten gelernt wird, werden die Tokenizer einmal getestet. Dafür wird ein Text encodiert und decodiert. Dann wird geprüft, ob der noch lesbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "some_tweets = tweets_from_all_years.sample(n=10, random_state=30)\n",
    "encoded = tokenizer(some_tweets['tweet'].to_list()[0], padding=True, max_length=MAX_TOKENS, pad_to_max_length=True,)\n",
    "decoded = tokenizer.decode(encoded['input_ids'])\n",
    "some_tokens=[]\n",
    "for i in some_tweets['tweet']:\n",
    "    some_tokens.append(' '.join(i.split(' ')[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoded = tokenizer(some_tweets['tweet'].to_list()[0], padding=True, max_length=MAX_TOKENS, pad_to_max_length=True,)\n",
    "decoded = tokenizer.decode(encoded['input_ids'])\n",
    "some_distil_tokens=[]\n",
    "for i in some_tweets['tweet']:\n",
    "    some_distil_tokens.append(' '.join(i.split(' ')[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tesla will make some merch',\n",
       " '0 to 155mph trap speed',\n",
       " 'Order at  <link>',\n",
       " '5 minutes from launch. Looks',\n",
       " 'Spacecraft arrives at Port of',\n",
       " 'Space Station tracking spaceship docking',\n",
       " \"Hope we're not just the\",\n",
       " 'Truth is a metaphorical concept',\n",
       " ' <image>',\n",
       " 'These are production design, unlike']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Erstellung von Datensätzen, die mit Tensorflow und dem Modell kompatibel sind ist eine größere Herausforderung. Dafür wird die `transformers` zugehörige Bibliothek `datasets` verwendet. Außerdem wird ein Train-und Test-Split erstellt. Das Test Split wird zum Hyperparameter-Tuning verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Set tweets to subset or to full dataset\n",
    "#tweet_ds = some_tweets\n",
    "import datasets\n",
    "tweet_ds = tweets_from_all_years\n",
    "# Damit sich der Datensatz nachher sicher in das Tensorflow Datenformat konvertieren lässt muss mit dem Datenset-Format der transformers library erstellt werden\n",
    "tweets_ds = datasets.Dataset.from_pandas(tweet_ds[['tweet']])\n",
    "\n",
    "tweets_ds = tweets_ds.train_test_split(test_size=0.2)\n",
    "MAX_TOKENS = max([len(tokenizer.encode(tweet, add_special_tokens=True)) for tweet in tweet_ds['tweet']])+2\n",
    "DISTIL_MAX_TOKENS = max([len(distil_tokenizer.encode(tweet, add_special_tokens=True)) for tweet in tweet_ds['tweet']])+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', '__index_level_0__'],\n",
       "    num_rows: 3912\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', '__index_level_0__'],\n",
       "    num_rows: 978\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die `prepare_text` Funktion wird später mit einer `map` Funktion verwendet um die Texte in token-sequenzen umzuwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## mit anpassungen übernommen aus https://data-dive.com/finetune-german-gpt2-on-tpu-transformers-tensorflow-for-text-generation-of-reviews\n",
    "def prepare_text(tweets:list, prep_tokenizer, prep_MAX_TOKENS):\n",
    "    # Einfügen der Prompts vor jeden Tweet\n",
    "    text = [BOS_TOKEN + tweet + EOS_TOKEN for tweet in tweets['tweet']]\n",
    "\n",
    "    tokenized = prep_tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,  # Only adds pad not eos and bos\n",
    "        max_length=prep_MAX_TOKENS,\n",
    "        truncation=True,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_tweets_ds = tweets_ds.map(\n",
    "    lambda x: prepare_text(x, distil_tokenizer,DISTIL_MAX_TOKENS),\n",
    "    batched=True,\n",
    "    #num_proc=4,\n",
    "    # ursprünglich spalten entfernen\n",
    "    remove_columns=['tweet','__index_level_0__'],\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_ds = tweets_ds.map(\n",
    "    lambda x: prepare_text(x, tokenizer, MAX_TOKENS),\n",
    "    batched=True,\n",
    "    #num_proc=4,\n",
    "    remove_columns=['tweet','__index_level_0__'],\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der fertige Text wird zum Test nochmal dekodiert. Nun sind auch Padding Tokens vorhanden, um alle Sequenzen auf die gleiche Länge, und damit in ein für das Modell zu verarbeitende Format zu bringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|elontext|>Am getting lots of questions about the big Supercharger announcement. Aiming to do that the week after next.<|endoftext|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tweets_ds['train']:\n",
    "    print(tokenizer.decode(i['input_ids']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Datenset muss in das von Tensorflow Datenformat konvertiert werden. Dafür bietet `datasets` eine vorgefertigte Funktion und es muss lediglich eine funktion drum herum geschrieben werden, die das Schema an das Modell anpasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "DataCollators sind eine Funktion von `datasets` um weitere funktionen zu der Konvertierungs-Pipeline hinzuzufügen. In diesem Fall ist er nur ein Hilfswerkzeug zur generierung der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = tweets_ds['train'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test = tweets_ds['test'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_train = distil_tweets_ds['train'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "distil_test = distil_tweets_ds['test'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Für das Training werden einige Hyperparameter benötigt, die nicht manuell angepasst werden. Zudem wird der Datensatz in Batches unterteilt, damit Stochastic Gradient verwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train)\n",
    "DISTIL_BUFFER_SIZE = len(distil_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_train = distil_train.shuffle(len(distil_train))\n",
    "train = train.shuffle(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Modelle von `transformers` sind mit Tensorflow kompatibel und lassen sich über die Bibliothek einfach laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "distil_model = TFGPT2LMHeadModel.from_pretrained(\n",
    "    \"distilgpt2\",\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "\n",
    "# Weil die anzahl der Standard Tokens im Tokenizer angepasst wurde, müssen auch die Größen der ersten Layer angepasst werden.\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "distil_model.resize_token_embeddings(len(distil_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der am meisten genutzte Optimizer ist Adam. Dieser wird auch in GPT-2 und dementprechen duach hier verwendet. Die Parameter sind die, die auch im Grundtraining von Tensorflow verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124442880 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,442,880\n",
      "Trainable params: 124,442,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 81915648  \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,915,648\n",
      "Trainable params: 81,915,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distil_optimizer = AdamWeightDecay(learning_rate=1e-6, weight_decay_rate=0.01)\n",
    "distil_model.compile(optimizer=distil_optimizer)\n",
    "distil_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie zu sehen, hat das `distil_model` deutlich weniger Parameter als das normale Modell. In diesem Fall sind es aber nicht wie angegeben die Häflte sondern etwas mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der `fit` Funktion wird das Training gestartet. Bei GPT-2 dauert es etwa 1-2h auf einem MacBook Pro mit Intel Core i9 ohne GPU Beschleunigung. Mit der Hardware Beschleunigung einer GTX 1070 lässt sich diese Zeit auf wenige Minuten kürzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "244/244 [==============================] - 66s 203ms/step - loss: 2.3092\n",
      "Epoch 2/6\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 1.2153\n",
      "Epoch 3/6\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 1.0298\n",
      "Epoch 4/6\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 1.0258\n",
      "Epoch 5/6\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.9704\n",
      "Epoch 6/6\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.9624\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(\n",
    "    train.repeat(),\n",
    "    epochs=6,\n",
    "    steps_per_epoch=BUFFER_SIZE / BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Modell lässt sich speichern, die Funktion sind aber auskommentiert, damit nicht aus versehen ein exisiterendes Modell überschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"./MUSK_GPT_UNOPTIMIZED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Training von GPT-2 dauert mit dem MacBook unter 15 Minuten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'labels': TensorSpec(shape=(4, None), dtype=tf.int64, name=None), 'input_ids': TensorSpec(shape=(4, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(4, None), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "244/244 [==============================] - 39s 161ms/step - loss: 1.8267 - val_loss: 1.7123\n",
      "Epoch 2/6\n",
      "244/244 [==============================] - 39s 159ms/step - loss: 1.7179 - val_loss: 1.5952\n",
      "Epoch 3/6\n",
      "244/244 [==============================] - 39s 159ms/step - loss: 1.5829 - val_loss: 1.5181\n",
      "Epoch 4/6\n",
      "244/244 [==============================] - 39s 159ms/step - loss: 1.5108 - val_loss: 1.4564\n",
      "Epoch 5/6\n",
      "244/244 [==============================] - 40s 162ms/step - loss: 1.4772 - val_loss: 1.3998\n",
      "Epoch 6/6\n",
      "244/244 [==============================] - 39s 160ms/step - loss: 1.4880 - val_loss: 1.3570\n"
     ]
    }
   ],
   "source": [
    "distil_model_hist = distil_model.fit(\n",
    "    distil_train.repeat(),\n",
    "    epochs=6,\n",
    "    steps_per_epoch= DISTIL_BUFFER_SIZE / BATCH_SIZE,\n",
    "    validation_data=distil_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#distil_model.save_pretrained(\"./MUSK_DISTIL_GPT_UNOPTIMIZED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameter Optimierung\n",
    "Hyperparameter Optimierung hat bei generativen Sprachemodellen nur einen geringen Einfluss. Ein Modell ist aufgrund schlechterer Metriken, in der Wahrnehmung eines Menschen zwangsläufig schlechter. Im Voraus lässt sich dazu allerdings kein Beurteilung machen. Sie wird aber trotzdem durchgeführt, weil sie für Machine Learning im allgemeinen obligatorisch ist. In diesem Fall wird das Framework KerasTrainer verwendet. Die Parameter die optimiert werden sollen sind die Batch Size, die Learning Rate, der Weight Decay und die anzahl der Epochen. Aufgrund des hohen Zeitaufwandes und des hohen Energieverbrauchs des Hyperparametertunings, gibt es nur einen sehr eng begrenzten Suchbereich. Dieser wird auch nicht erweitert, wenn die optimalen Werte ganz außen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#tunable parameters\n",
    "batch_size=16\n",
    "lr=2e-5\n",
    "num_train_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#https://wandb.ai/amogkam/transformers/reports/Hyperparameter-Optimization-for-Huggingface-Transformers--VmlldzoyMTc2ODI\n",
    "class Musk_Model(kt.HyperModel):\n",
    "\n",
    "    def __init__(self, huggingface_model='gpt2', name=None, tunable=True):\n",
    "        self.huggingface_model = huggingface_model\n",
    "        super().__init__(name, tunable)\n",
    "\n",
    "    def build(self, hp: kt.HyperParameters):\n",
    "        self.BATCH_SIZE = hp.Choice('batch_size',[4,8,16,32])\n",
    "        model = TFGPT2LMHeadModel.from_pretrained(\n",
    "            self.huggingface_model,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "        )\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        optimizer = AdamWeightDecay(learning_rate=hp.Choice('learning_rate', [2e-5, 3e-5, 5e-5, 7e-5]), weight_decay_rate=hp.Choice('weight_decay_rate',[0.0,0.01, 0.001,0.1]))\n",
    "        model.compile(optimizer=optimizer)\n",
    "        return model\n",
    "    def fit(self, hp: kt.HyperParameters, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            train.repeat(),\n",
    "            batch_size= self.BATCH_SIZE,\n",
    "            epochs=hp.Int('epochs',min_value=2, max_value=8),\n",
    "            steps_per_epoch=BUFFER_SIZE / self.BATCH_SIZE,\n",
    "            validation_data=test,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Als Optimierungsalgorithmus wird Bayesche Optimierung genutzt. Dies ist eine gute Balance zwischen Zeitaufwand, Entwicklungsaufwand und Qualität der Ergebnisse. Mit `val_loss` als objective wird der Validierungsdatensatz als Zielwert verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "batch_size (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 8, 16, 32], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 2e-05, 'conditions': [], 'values': [2e-05, 3e-05, 5e-05, 7e-05], 'ordered': True}\n",
      "weight_decay_rate (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.01, 0.001, 0.1], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel=Musk_Model(),\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=8,\n",
    "    overwrite=True,\n",
    "    directory=\"hyper-opt/\",\n",
    "    project_name=\"tune_tweet_generation\",\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 04m 20s]\n",
      "val_loss: 0.9074983596801758\n",
      "\n",
      "Best val_loss So Far: 0.8868565559387207\n",
      "Total elapsed time: 00h 44m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search()\n",
    "best_hp: kt.engine.hyperparameters.HyperParameters = tuner.get_best_hyperparameters()[0]\n",
    "best_hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyper_model = Musk_Model()\n",
    "optimized_model = hyper_model.build(best_hp)\n",
    "optimized_hist = hyper_model.fit(best_hp,optimized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#optimized_model.save_pretrained(\"./MUSK_GPT_OPTIMIZED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier lässt sich der Loss über den Zeitraum aller Iterationen beim optimiertenModell betrachten. Der Validierungs-Datensatz wird dabei immer nur ein Wenig besser, während das Modell im Trainingsdatensatz schnell besser und am Ende ein wenig schlechter wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(optimized_hist.history['loss'], label=\"Loss über die Epochen\")\n",
    "plt.plot(optimized_hist.history['val_loss'], label=\"Validierungs-Loss über die Epochen\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch das Tuning der Hyperparameter wird mit \"distilgpt2\" wiederholt. Die benötigte Zeit ist hiet deutlich geringer. Zur Vergleichbarkeit werden aber auch hier die gleichen Strategien angewendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_tuner = kt.BayesianOptimization(\n",
    "    hypermodel=Musk_Model(huggingface_model='distilgpt2'),\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=8,\n",
    "    overwrite=True,\n",
    "    directory=\"hyper-opt/\",\n",
    "    project_name=\"tune_distil_tweet_generation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 02m 30s]\n",
      "val_loss: 0.9383436441421509\n",
      "\n",
      "Best val_loss So Far: 0.9278596639633179\n",
      "Total elapsed time: 00h 28m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "distil_tuner.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4,\n",
       " 'learning_rate': 7e-05,\n",
       " 'weight_decay_rate': 0.1,\n",
       " 'epochs': 8}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_d_hp: kt.engine.hyperparameters.HyperParameters = distil_tuner.get_best_hyperparameters()[0]\n",
    "best_d_hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "244/244 [==============================] - 79s 261ms/step - loss: 1.7410 - val_loss: 1.0410\n",
      "Epoch 2/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 1.0790 - val_loss: 0.9673\n",
      "Epoch 3/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.9805 - val_loss: 0.9487\n",
      "Epoch 4/8\n",
      "244/244 [==============================] - 62s 253ms/step - loss: 0.9648 - val_loss: 0.9196\n",
      "Epoch 5/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8874 - val_loss: 0.9142\n",
      "Epoch 6/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8540 - val_loss: 0.9032\n",
      "Epoch 7/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8446 - val_loss: 0.8976\n",
      "Epoch 8/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8460 - val_loss: 0.8940\n"
     ]
    }
   ],
   "source": [
    "distil_hyper_model = Musk_Model()\n",
    "optimized_distil_model = distil_hyper_model.build(best_d_hp)\n",
    "optimized_distil_hist = distil_hyper_model.fit(best_d_hp,optimized_distil_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Beide Modelle erreichen letztendlich einen ähnlichen Validation loss, dies sagt aber wenig über die allgemeine Qualität des Modells aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#optimized_distil_model.save_pretrained('./MUSK_DISTIL_GPT_OPTIMIZED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelle laden und Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Modelle können nun geladen werden und Ergebnisse produziert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_GPT_OPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_DISTIL_GPT_UNOPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_GPT_OPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_DISTIL_GPT_OPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_GPT_OPTIMIZED\")\n",
    "distil_model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_DISTIL_GPT_UNOPTIMIZED\")\n",
    "optimized_model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_GPT_OPTIMIZED\")\n",
    "optimized_distil_model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_DISTIL_GPT_OPTIMIZED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<|elontext|>\"\n",
    "default_gen = pipeline(\"text-generation\", model='gpt2')\n",
    "gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "distil_gen= pipeline('text-generation', model=distil_model, tokenizer=distil_tokenizer)\n",
    "opt_gen = pipeline('text-generation', model=optimized_model, tokenizer=tokenizer)\n",
    "opt_distil_gen = pipeline('text-generation', model=optimized_distil_model, tokenizer=distil_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modell Evaluierung\n",
    "Mit den zuvor festgelegt Prompt lässt sich nun Text generieren. Die Texte von GPT-2 sind zwar manchmal etwas verwirrend und ergeben inhaltlich keinen besonderen Sinn, sind aber grammatikalisch meißt korrekt und passen auch zu Elon Musks sonstigen Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|>\\n\\n<|b| | | a| |.\\n\\n:a b|\\n\\n.:c\\n\\n.||.\\n\\n|:m b|\\n\\n.|c\\n\\n'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default model\n",
    "default_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#default model mit tweet prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|>@jones3 @Gatorade No problem'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainiertes modell\n",
    "gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#trainiertes modell mit tweet prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|>@IDGAA That would be worth a lot of money.'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainiertes modell mit hyperparameter tuning\n",
    "opt_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Distil-GPT-2 Modell ist im Gegensatz dazu eher unbrauchbar. Die Texte ergeben keinen Sinn und haben keinen Zusammenhang. Das zeigt sich vor allem auch darin, dass die Texte grammatikalische starke Schwächen haben, was bei GPT2 nicht der Fall ist.\n",
    " Dieser qualitative Unterschied bestätigt, dass der Loss kein besonders guter Indikator für die Qualität des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|> is a personal injury, and is a with a non-cabin in the trunk, and is a one-piece container.'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainiertes distilgpt2 modell mit hyperparamerter tuning\n",
    "distil_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das wird mit dem optimierten Modell ein wenig besser, allerdings gibt es auch hier keinen wirklichen Zusammenhang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"<|elontext|>First time making a Model 3.0. Autopilot is great. Hopefully by then we're all fine.\"}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainiertes distilgpt2 modell mit hyperparamerter tuning mit tweet prompt\n",
    "opt_distil_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stattdessen ist eine Evaluierung interessant, in der getestet wird, ob eine Gruppe aus Studierenden der Wirtschaftsinformatik die generierten Tweets von den echten Tweets unterscheiden können.\n",
    "Für diese Evaluierung wurden zufällig Paare aus echten Tweets und und falschen Tweets erstellt. Den Studierenden wurde der Auftrag gegeben, den echten Tweet von beiden zu bestimmen und dafür auf einer Website abzustimmen.  Die Ergebnisse wurden in einer Datenbank gespeichert. Das genutzte Modell ist dafür das erste GPT-2 Modell ohne Hyperparameter Tuning, weil dieses zu dem Zeitpunk noch nicht fertig war."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Einige Beispielpaare sind:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generierter Tweet \"The only way to reach me is to tweet @barned_slaming “@chris_nho\"\n",
    "Echter Tweet: \"Which leads me to my next subject of gun control ... just kidding\"\n",
    "\n",
    "Generierter Tweet: \"️ Thanks for a great AMA!\",\"real\":\n",
    "Echter Tweet: \"1st firing of Falcon 9-R advanced prototype rocket. Over 1M lbs thrust, enough to lift skyscraper  http://t.co/AUCsWTw77E\"\n",
    "\n",
    "Generierter Tweet: \"I'd love to make a nice big rock on ice! Maybe some great ice cream!\"\n",
    "Echter Tweet:\"@MaxMBerger The collective wisdom of the market is usually (not always) better than the smartest govt regulator.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bei der Abstimmung konnte GPT-2 zwar in weniger Fällen täuschen, dies ist aber zu erwarten, weil GPT-2 natürlich kein echter Mensch ist sondern noch immer ein Sprachmodell, das nur Sprache aber keine Inhalte versteht. Trotzdem ist die Anzahl der als falsch als echt benannten Tweets betrachtlich und Zeigt auch, dass es nicht unmöglich ist Menschen zu täuschen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Auswahl eines Modells für eine Evaluierung mit Testsubjekten\n",
    "Mit einer Gruppe Studierender soll evaluiert werden ob es mit dem Modell möglich ist tweets zu generieren, die von echten Tweets nicht zu unterscheiden sind, dafür soll eines der Modelle ausgewählt werden.\n",
    "Weil zum Zeitpunkt des Test noch die Hyperparameter Optimierung lief, wurde das erste Modell verwendet. Dieses ist allerdings asugereift genug, um Tweets zu generieren.\n",
    "Die Gruppe Studierender öffnet eine Website, auf der immer jeweils 2 Tweets präsentiert werden. Die Studierenden sollen auswählen, von welchem beider Tweets sie glauben, dass er echt. Es existiert die Möglichkeit, dass die Tweets auch live generiert werden. Das genutzte Modell generiert allerdings gelegntlich Tweets die leer sind oder vollständig sinnlos sind. Diese automatisch herauszufiltern wäre ein großer Aufwand gewesen. Aus diesem Grund werden für das Experiment Tweets vorher generiert und auf 65 Tweets gekürzt, die syntaktisch Sinn ergeben. Diese wurden dann einem echten Tweet zugeordnert und als Paar in der Datenbank gespeichert, damit sie miteinander vergleichbar sind.\n",
    "\n",
    "Insgesamt wurde 78 Mal geraten, es gab also auch Tweets, die doppelt verwendet wurden. Dabei wurde 34 Mal der Falsche und 44 Mal der richtige Tweet ausgewählt. Ein optimales Ergebnis wäre 39 zu 39 gewesen\n",
    "\n",
    "![Statistik Raten](experiment.png)\n",
    "\n",
    "\n",
    "Dieses Ergebnis lässt sich aus zwei Perspektiven betrachten. Aus der Sicht, dass es sich um ein Modell handelt dass menschliche Sprache imitieren soll, sind die Ergebnisse relativ gut, weil es sich dabei um eine komplizierte Aufgabe handelt. Aus der Sicht, dass den 'Probanden' aber nur ein kurzer Text gegeben wird, anhand dessen die Echtheit allgemein schlecht zu unterscheiden ist, wäre ein Ergebniss näher am Optimimum wünschenswert gewesen.\n",
    "\n",
    "Einige Beispiele für generierte Tweets, die für echte Tweets gehalten wurden:\n",
    "\n",
    "Echt:\"My first prediction of 2012 has come true: ouch, my head hurts.\n",
    "\n",
    "Falsch: \" @JLobuchan @Yahoo! Will do a live demo at the Air Force Museum tonight at 3pm, where all 50 astronauts will have the opportunity to speak. Thanks to everyone!\"\n",
    "\n",
    "\n",
    "\n",
    "Echt:\"No kidding\"\n",
    "\n",
    "Falsch:\"I'm a proud Canadian proud of the incredible work of @Yahoo! I hope you guys can find a cure for cancer.  link\"\n",
    "\n",
    "\n",
    "\n",
    "Echt: \"My @SpaceX team is not working for  link link\"\n",
    "\n",
    "Falsch: \"Tesla articles 30 mins apart: \"This Stock is Screaming Buy\"  link and \"This Stock Could Get DESTROYED\"  link\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fazit und Ausblick\n",
    "In dieser Arbeit lies sich zeigen, dass State-of-the-Art Machine Learning Modelle dazu genutzt werden können kurze Texte zu generieren, mit denen sich Menschen in ein paar Fällen überzeugen lassen sie seien echt. Das zeigt auch, dass kurze Texte mit wenige großem Zusammenhang sehr einfach zu generieren sind\n",
    " Allerdings lassen sich noch viele Verbeserung auf dieses Modell anwenden. Es existieren noch viele andere Sprache-Modelle, die nicht verglichen wurden. Zudem gibt es verschiedene Arten, den Trainings-Datensatz zu struktuieren, was auch Einfluss auf das spätere Modell hat. Ein weiteres interessantes Experiment ist die Generierung von Antworten auf andere Tweets anhand bisheriger Antworten. Ein interessantes Experiment wäre es, mit dem Modell einen Bot zu entwickeln, der einen Twitter-Account als Elon Musk betreibt. Dies ist auch der einzige tatsächliche Use-Case, der für diese Art von Modell vorstellbar ist. Generell ist das weniger als ein sinnvolles Projekt zu sehen, sondern als eine Art Benchmark, in dem zu sehen ist, was mit heutigen Modell möglich ist. In diesem Fal hat sich gezeigt, dass Sprachmodelle zu sehr viel fähig sind, weshalb es viele Einsatzfelder für sie gibt."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b757419f8e9653efa3b1d0ab3e43e629cdfff8f48cf8c1e8bcae685186face11"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}