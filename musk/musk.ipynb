{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Warum ist es wichtig Elon Musk Tweets zu generieren?\n",
    "Elon Musk ist seit 2020 der reichste Mann der Welt. Zus√§tzlich ist er eine der einflussreichsten Personen auf der Plattform und baut diesen Einfluss damit aus, dass der seit 2022 der gr√∂√üte Anteilseigner der Plattform ist. Bei den Theman Unternehmensanteile, Elon Musk und Twitter wird es auch abseits von Elon Musks pers√∂nlicher Finanzlage interessant. Musk ist bekannt daf√ºr, in den letzten Jahren mit seinen Tweets Aktienkurse beeinflusst zu haben. Er hat beispielsweise 2018 getwittert, dass er Tesla bei einem Aktienpreis von $420 wieder zu einem privaten, nicht gehandelten, Unternehmen machen w√ºrde. Dadurch stieg der Preis f√ºr die Aktie in den folgenden Tagen signifikant an [Vgl. SEC 2018](https://www.sec.gov/news/press-release/2018-219)\n",
    "Wer finanzielle Interessen hat, k√∂nnte sich davon ausgehen damit besch√§ftigen, ein System zu entwickeln, das anhand von Elon Musks Meinung Aktien und Optionen kauft.\n",
    "Wer finanzielle Interessen hat, sollte sich aber vielleicht auch nicht mit Elon Musks Tweets besch√§ftigen und denken, dass er anhand dessen der n√§chste Warren Buffet wird, sondern arbeiten. Viel interessanter w√§re es doch eigene Tweets zu generieren. Einen Wert f√ºr die Gesellschaft hat das nicht. Damit l√§sst sich dennoch eine interessante Beobachtung machen. Textinhalte bei Twitter sind auf 240 Zeichen begrenzt. Komplexe Zusammenh√§nge mit verschiedenen Aussagen in einzelnen Tweets sind dadurch nur begrenzt m√∂glich. Die meisten Sprachmodelle haben auch genau damit ein Problem, lange zusammenh√§ngende Texte zu generieren in denen verschiedene Aussagen koherent sind.\n",
    "Die Idee Tweets mit einem Sprachmodell zu generieren ist also eigentlich sehr naheliegend und dies auch nicht der erste Ansatz. Diese fokussieren sich aber alle auf Twitter im Allgemeinen und nicht spezifisch auf das Profil eines Nutzers oder eine Nutzerin. Das Interessante an einem einzelnen Profil, ist dass die Sprache und die Gedanken eines einzelnen Menschen nachgestellt werden und nicht einer ganzen Gruppe. Genau ein Mensch nicht wie alle Menschen auf Twitter spricht, soll das Model auch nicht lernen wie alle Menschen zu sprechen, sondern eben nur wie ein Mensch zu sprechen.\n",
    "### Elon Musks Twitter Profil\n",
    "![Elon Musks Twitter Profil](elonmusk_twitter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ole\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ole\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras_tuner.engine.hyperparameters\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import DefaultDataCollator, pipeline, AutoTokenizer, AutoModelForCausalLM, TFGPT2LMHeadModel, AdamWeightDecay, TFAutoModelForCausalLM\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pr√ºfen der Hardwarebeschleunigung\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.test.gpu_device_name()\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zur Datenbeschaffung l√§sst sich theoretisch die API von Twitter nutzen, allerdings gibt es einen [Kaggle-Datensatz](https://www.kaggle.com/datasets/ayhmrba/elon-musk-tweets-2010-2021), in dem die Tweets der API bereits aufbereitet sind. Der Datensatz enth√§lt zweets von 2010 bis 2022 in einzelnen Dateien. Alle dateien werden eingelesen und in einen DataFrame zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_from_years = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in os.listdir('musktweets'):\n",
    "    year = i.rstrip('.csv')\n",
    "    if i == '2021.csv' or i == '2022.csv':\n",
    "        tweets_from_years[year] = pd.read_csv('musktweets/'+i)\n",
    "    else:\n",
    "        tweets_from_years[year] = pd.read_csv('musktweets/'+i, index_col='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Tabellen ab 2020 haben ein leicht ver√§ndertes Schema und m√ºssen an die anderen angepasst werden. Au√üerdem werden nur bestimmte Felder zu weiteren Arbeit genutzt und die relativ h√§ufigen Duplikate im Datensatz entfernt. Insgesamt sind das nur kosmetische Anpassungen, zur leichteren Arbeit mit dem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'conversation_id', 'created_at', 'date', 'timezone', 'place',\n",
      "       'tweet', 'language', 'hashtags', 'cashtags', 'user_id', 'user_id_str',\n",
      "       'username', 'name', 'day', 'hour', 'link', 'urls', 'photos', 'video',\n",
      "       'thumbnail', 'retweet', 'nlikes', 'nreplies', 'nretweets', 'quote_url',\n",
      "       'search', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n",
      "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
      "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
      "       'urls', 'photos', 'replies_count', 'retweets_count', 'nlikes',\n",
      "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
      "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n",
      "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
      "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
      "       'urls', 'photos', 'replies_count', 'retweets_count', 'nlikes',\n",
      "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
      "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
      "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
      "       'trans_dest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for year in tweets_from_years:\n",
    "    if year == '2022' or year == '2021' or year == '2020':\n",
    "        tweets_from_years[year].rename(columns={'likes_count':'nlikes'}, inplace=True)\n",
    "        print(tweets_from_years[year].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1476662222617251846</td>\n",
       "      <td>1476620230692679680</td>\n",
       "      <td>2021-12-31 01:11:23 Arabian Standard Time</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>01:11:23</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'roshanpateI', 'name': 'Rosha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1476656306610216960</td>\n",
       "      <td>1476644467578859528</td>\n",
       "      <td>2021-12-31 00:47:53 Arabian Standard Time</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>00:47:53</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'tesla_raj', 'name': 'Tesla R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1476651519986614281</td>\n",
       "      <td>1476252898115964928</td>\n",
       "      <td>2021-12-31 00:28:51 Arabian Standard Time</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>00:28:51</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'CSmithson80', 'name': 'Chris...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1476619907076923398</td>\n",
       "      <td>1476252898115964928</td>\n",
       "      <td>2021-12-30 22:23:14 Arabian Standard Time</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>22:23:14</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1476618021024190474</td>\n",
       "      <td>1476252898115964928</td>\n",
       "      <td>2021-12-30 22:15:45 Arabian Standard Time</td>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>22:15:45</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'mims', 'name': 'Christopher ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>1345384139969552389</td>\n",
       "      <td>1345382294966571008</td>\n",
       "      <td>2021-01-02 18:59:09 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>18:59:09</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'flcnhvy', 'name': 'Viv ‚ú∂', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>1345382294966571008</td>\n",
       "      <td>1345382294966571008</td>\n",
       "      <td>2021-01-02 18:51:49 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>18:51:49</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>1345344958710992897</td>\n",
       "      <td>1345334831719337984</td>\n",
       "      <td>2021-01-02 16:23:28 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>16:23:28</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'newscientist', 'name': 'New ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>1345208391958888448</td>\n",
       "      <td>1344675033231237120</td>\n",
       "      <td>2021-01-02 07:20:48 Arabian Standard Time</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>07:20:48</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'comma_ai', 'name': 'comma', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>1344810193952014336</td>\n",
       "      <td>1344518758707113986</td>\n",
       "      <td>2021-01-01 04:58:30 Arabian Standard Time</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>04:58:30</td>\n",
       "      <td>400</td>\n",
       "      <td>44196397</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'PPathole', 'name': 'Pranay P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3115 rows √ó 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id      conversation_id  \\\n",
       "0     1476662222617251846  1476620230692679680   \n",
       "1     1476656306610216960  1476644467578859528   \n",
       "2     1476651519986614281  1476252898115964928   \n",
       "3     1476619907076923398  1476252898115964928   \n",
       "4     1476618021024190474  1476252898115964928   \n",
       "...                   ...                  ...   \n",
       "3110  1345384139969552389  1345382294966571008   \n",
       "3111  1345382294966571008  1345382294966571008   \n",
       "3112  1345344958710992897  1345334831719337984   \n",
       "3113  1345208391958888448  1344675033231237120   \n",
       "3114  1344810193952014336  1344518758707113986   \n",
       "\n",
       "                                     created_at        date      time  \\\n",
       "0     2021-12-31 01:11:23 Arabian Standard Time  2021-12-31  01:11:23   \n",
       "1     2021-12-31 00:47:53 Arabian Standard Time  2021-12-31  00:47:53   \n",
       "2     2021-12-31 00:28:51 Arabian Standard Time  2021-12-31  00:28:51   \n",
       "3     2021-12-30 22:23:14 Arabian Standard Time  2021-12-30  22:23:14   \n",
       "4     2021-12-30 22:15:45 Arabian Standard Time  2021-12-30  22:15:45   \n",
       "...                                         ...         ...       ...   \n",
       "3110  2021-01-02 18:59:09 Arabian Standard Time  2021-01-02  18:59:09   \n",
       "3111  2021-01-02 18:51:49 Arabian Standard Time  2021-01-02  18:51:49   \n",
       "3112  2021-01-02 16:23:28 Arabian Standard Time  2021-01-02  16:23:28   \n",
       "3113  2021-01-02 07:20:48 Arabian Standard Time  2021-01-02  07:20:48   \n",
       "3114  2021-01-01 04:58:30 Arabian Standard Time  2021-01-01  04:58:30   \n",
       "\n",
       "      timezone   user_id  username       name  place  ... geo source  \\\n",
       "0          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "1          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "2          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "4          400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "...        ...       ...       ...        ...    ...  ...  ..    ...   \n",
       "3110       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3111       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3112       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3113       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "3114       400  44196397  elonmusk  Elon Musk    NaN  ... NaN    NaN   \n",
       "\n",
       "     user_rt_id user_rt retweet_id  \\\n",
       "0           NaN     NaN        NaN   \n",
       "1           NaN     NaN        NaN   \n",
       "2           NaN     NaN        NaN   \n",
       "3           NaN     NaN        NaN   \n",
       "4           NaN     NaN        NaN   \n",
       "...         ...     ...        ...   \n",
       "3110        NaN     NaN        NaN   \n",
       "3111        NaN     NaN        NaN   \n",
       "3112        NaN     NaN        NaN   \n",
       "3113        NaN     NaN        NaN   \n",
       "3114        NaN     NaN        NaN   \n",
       "\n",
       "                                               reply_to  retweet_date  \\\n",
       "0     [{'screen_name': 'roshanpateI', 'name': 'Rosha...           NaN   \n",
       "1     [{'screen_name': 'tesla_raj', 'name': 'Tesla R...           NaN   \n",
       "2     [{'screen_name': 'CSmithson80', 'name': 'Chris...           NaN   \n",
       "3     [{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...           NaN   \n",
       "4     [{'screen_name': 'mims', 'name': 'Christopher ...           NaN   \n",
       "...                                                 ...           ...   \n",
       "3110  [{'screen_name': 'flcnhvy', 'name': 'Viv ‚ú∂', '...           NaN   \n",
       "3111                                                 []           NaN   \n",
       "3112  [{'screen_name': 'newscientist', 'name': 'New ...           NaN   \n",
       "3113  [{'screen_name': 'comma_ai', 'name': 'comma', ...           NaN   \n",
       "3114  [{'screen_name': 'PPathole', 'name': 'Pranay P...           NaN   \n",
       "\n",
       "      translate trans_src trans_dest  \n",
       "0           NaN       NaN        NaN  \n",
       "1           NaN       NaN        NaN  \n",
       "2           NaN       NaN        NaN  \n",
       "3           NaN       NaN        NaN  \n",
       "4           NaN       NaN        NaN  \n",
       "...         ...       ...        ...  \n",
       "3110        NaN       NaN        NaN  \n",
       "3111        NaN       NaN        NaN  \n",
       "3112        NaN       NaN        NaN  \n",
       "3113        NaN       NaN        NaN  \n",
       "3114        NaN       NaN        NaN  \n",
       "\n",
       "[3115 rows x 36 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_years['2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>photos</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4652</td>\n",
       "      <td>2010-06-04 18:31:57</td>\n",
       "      <td>https://twitter.com/elonmusk/status/15434727182</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-28 22:27:08</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1521536376...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TheOnion So true :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2011-12-27 23:38:55</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1518093150...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you ever wanted to know the *real* truth ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>2011-12-26 16:29:50</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1513389393...</td>\n",
       "      <td>['https://pbs.twimg.com/media/Ahmp9qtCAAAYPDX....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walked around a neighborhood recently rebuilt ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>2011-12-26 16:23:04</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1513372374...</td>\n",
       "      <td>['https://pbs.twimg.com/media/AhmoamaCQAANvSt....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was Xmas, so we brought presents for the ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34873</th>\n",
       "      <td>1023</td>\n",
       "      <td>473530</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477775713...</td>\n",
       "      <td>['https://pbs.twimg.com/media/FIIdLYoXoAEd2j_....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/LA9hPzVlGx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34874</th>\n",
       "      <td>1024</td>\n",
       "      <td>320201</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477706142...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let‚Äôs make the roaring 20‚Äôs happen!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34875</th>\n",
       "      <td>1025</td>\n",
       "      <td>66405</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477700424...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great work by Tesla team worldwide!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34876</th>\n",
       "      <td>1026</td>\n",
       "      <td>45704</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477096955...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BLKMDL3 @Tesla üî•</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34877</th>\n",
       "      <td>1027</td>\n",
       "      <td>4127</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1477080438...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'MiFSDBetaTester', 'name': 'R...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MiFSDBetaTester @WholeMarsBlog ü§£</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34878 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  nlikes                 date  \\\n",
       "0          0    4652  2010-06-04 18:31:57   \n",
       "1          0      12  2011-12-28 22:27:08   \n",
       "2          1      39  2011-12-27 23:38:55   \n",
       "3          2     155  2011-12-26 16:29:50   \n",
       "4          3     158  2011-12-26 16:23:04   \n",
       "...      ...     ...                  ...   \n",
       "34873   1023  473530           2022-01-03   \n",
       "34874   1024  320201           2022-01-02   \n",
       "34875   1025   66405           2022-01-02   \n",
       "34876   1026   45704           2022-01-01   \n",
       "34877   1027    4127           2022-01-01   \n",
       "\n",
       "                                                    link  \\\n",
       "0        https://twitter.com/elonmusk/status/15434727182   \n",
       "1      https://twitter.com/elonmusk/status/1521536376...   \n",
       "2      https://twitter.com/elonmusk/status/1518093150...   \n",
       "3      https://twitter.com/elonmusk/status/1513389393...   \n",
       "4      https://twitter.com/elonmusk/status/1513372374...   \n",
       "...                                                  ...   \n",
       "34873  https://twitter.com/elonmusk/status/1477775713...   \n",
       "34874  https://twitter.com/elonmusk/status/1477706142...   \n",
       "34875  https://twitter.com/elonmusk/status/1477700424...   \n",
       "34876  https://twitter.com/elonmusk/status/1477096955...   \n",
       "34877  https://twitter.com/elonmusk/status/1477080438...   \n",
       "\n",
       "                                                  photos  \\\n",
       "0                                                     []   \n",
       "1                                                     []   \n",
       "2                                                     []   \n",
       "3      ['https://pbs.twimg.com/media/Ahmp9qtCAAAYPDX....   \n",
       "4      ['https://pbs.twimg.com/media/AhmoamaCQAANvSt....   \n",
       "...                                                  ...   \n",
       "34873  ['https://pbs.twimg.com/media/FIIdLYoXoAEd2j_....   \n",
       "34874                                                 []   \n",
       "34875                                                 []   \n",
       "34876                                                 []   \n",
       "34877                                                 []   \n",
       "\n",
       "                                                reply_to  retweet  source  \\\n",
       "0                                                     []    False     NaN   \n",
       "1                                                     []    False     NaN   \n",
       "2                                                     []    False     NaN   \n",
       "3                                                     []    False     NaN   \n",
       "4                                                     []    False     NaN   \n",
       "...                                                  ...      ...     ...   \n",
       "34873                                                 []    False     NaN   \n",
       "34874                                                 []    False     NaN   \n",
       "34875                                                 []    False     NaN   \n",
       "34876  [{'screen_name': 'BLKMDL3', 'name': 'Zack', 'i...    False     NaN   \n",
       "34877  [{'screen_name': 'MiFSDBetaTester', 'name': 'R...    False     NaN   \n",
       "\n",
       "                                                   tweet  video  \n",
       "0      Please ignore prior tweets, as that was someon...      0  \n",
       "1                                   @TheOnion So true :)      0  \n",
       "2      If you ever wanted to know the *real* truth ab...      0  \n",
       "3      Walked around a neighborhood recently rebuilt ...      1  \n",
       "4      It was Xmas, so we brought presents for the ki...      1  \n",
       "...                                                  ...    ...  \n",
       "34873                            https://t.co/LA9hPzVlGx      1  \n",
       "34874                Let‚Äôs make the roaring 20‚Äôs happen!      0  \n",
       "34875                Great work by Tesla team worldwide!      0  \n",
       "34876                                  @BLKMDL3 @Tesla üî•      0  \n",
       "34877                  @MiFSDBetaTester @WholeMarsBlog ü§£      0  \n",
       "\n",
       "[34878 rows x 10 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year in tweets_from_years:\n",
    "    tweets_from_years[year] = tweets_from_years[year][['nlikes','date', 'link','photos','reply_to','retweet','source','tweet','video']]\n",
    "tweets_from_all_years = pd.concat([tweets_from_years[year] for year in tweets_from_years.keys()])\n",
    "tweets_from_all_years = tweets_from_all_years.reset_index()\n",
    "tweets_from_all_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ein paar Typconvertierungen\n",
    "tweets_from_all_years['date'] = tweets_from_all_years['date'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_from_all_years = tweets_from_all_years.drop_duplicates(subset='tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den 15219 Tweets gibt es 10329 Antworten auf Tweets von anderen NutzerInnen. In der Wortwahl sind Antworten aber anders als eigenst√§ndige Tweets, weil Menschen ihre Sprache unterbewusst an die Sprache der anderen Menschen anpasst. Ohne den Kontext des urspr√ºnglichen Tweet, ergibt ein Tweet au√üerdem inhaltlich auch nur wenig Sinn. Die automatische Generierung von Antworten w√§re aber ein interessantes separates Projekt. In diesem Projekt werden aber nur eigenst√§ndige Tweets generiert, weshalb Tweets, die Antworten auf andere Tweets sind entfernt werden. In diesem Punkt unterscheidet sich das Projekt auch von einem anderen Projekt mit diesem Datensatz, in dem Tweets generiert wurden. In diesem Projekt waren auch antworten enthalten, weshalb prim√§r fiktive Antworten auf andere Nutzer generiert werden. Es bleiben also 4890 Tweets f√ºr das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_from_all_years = tweets_from_all_years[(tweets_from_all_years['reply_to']=='[]') & (tweets_from_all_years['retweet']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_all_years[(tweets_from_all_years['retweet']!=False)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "F√ºr das Training werden au√üerdem Links durch einen Link Tag 'link' ersetzt, weil mit einem Modell nat√ºrlich keine echten Links generiert werden k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url_re = re.compile(r\"https?:\\/\\/\\S*\")\n",
    "tweets_from_all_years['tweet']=tweets_from_all_years.apply(lambda x: url_re.sub('<link>',x['tweet'] if x['video'] == 0 else url_re.sub('<image>',x['tweet'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>photos</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>522</td>\n",
       "      <td>144</td>\n",
       "      <td>2016-04-30 01:14:50</td>\n",
       "      <td>https://twitter.com/elonmusk/status/7262182181...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@phillipcjackson turns out it doesn't need sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>1143</td>\n",
       "      <td>114300</td>\n",
       "      <td>2019-07-27 18:15:32</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1155179932...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ability to stream YouTube &amp;amp; Netflix when c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>1753</td>\n",
       "      <td>18065</td>\n",
       "      <td>2019-05-12 01:54:33</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1127391581...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Much will likely go wrong on 1st mission. Also...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>1496</td>\n",
       "      <td>22488</td>\n",
       "      <td>2018-06-10 06:33:43</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1005699514...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is why I‚Äôm not impressed when reporters w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>72</td>\n",
       "      <td>509</td>\n",
       "      <td>2014-08-03 19:11:50</td>\n",
       "      <td>https://twitter.com/elonmusk/status/4960105723...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While on the subject of AI risk, Our Final Inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>173</td>\n",
       "      <td>21</td>\n",
       "      <td>2012-04-30 20:10:22</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1970553142...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T minus five minutes to flame</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33939</th>\n",
       "      <td>89</td>\n",
       "      <td>205929</td>\n",
       "      <td>2022-02-23 00:00:00</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1496252264...</td>\n",
       "      <td>['https://pbs.twimg.com/media/FMPBgHWWUAoro-w....</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;image&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21311</th>\n",
       "      <td>2293</td>\n",
       "      <td>102318</td>\n",
       "      <td>2020-04-30 17:54:59</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1255918585...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classifying all deaths as corona even if coron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31340</th>\n",
       "      <td>605</td>\n",
       "      <td>48501</td>\n",
       "      <td>2021-11-03 00:00:00</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1455980193...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And Mars  &lt;link&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33332</th>\n",
       "      <td>2597</td>\n",
       "      <td>99495</td>\n",
       "      <td>2021-03-12 00:00:00</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1370449655...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Both do mining &amp;amp; use blocks &amp;amp; chains</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  nlikes                date  \\\n",
       "3776     522     144 2016-04-30 01:14:50   \n",
       "11849   1143  114300 2019-07-27 18:15:32   \n",
       "12459   1753   18065 2019-05-12 01:54:33   \n",
       "9917    1496   22488 2018-06-10 06:33:43   \n",
       "1150      72     509 2014-08-03 19:11:50   \n",
       "201      173      21 2012-04-30 20:10:22   \n",
       "33939     89  205929 2022-02-23 00:00:00   \n",
       "21311   2293  102318 2020-04-30 17:54:59   \n",
       "31340    605   48501 2021-11-03 00:00:00   \n",
       "33332   2597   99495 2021-03-12 00:00:00   \n",
       "\n",
       "                                                    link  \\\n",
       "3776   https://twitter.com/elonmusk/status/7262182181...   \n",
       "11849  https://twitter.com/elonmusk/status/1155179932...   \n",
       "12459  https://twitter.com/elonmusk/status/1127391581...   \n",
       "9917   https://twitter.com/elonmusk/status/1005699514...   \n",
       "1150   https://twitter.com/elonmusk/status/4960105723...   \n",
       "201    https://twitter.com/elonmusk/status/1970553142...   \n",
       "33939  https://twitter.com/elonmusk/status/1496252264...   \n",
       "21311  https://twitter.com/elonmusk/status/1255918585...   \n",
       "31340  https://twitter.com/elonmusk/status/1455980193...   \n",
       "33332  https://twitter.com/elonmusk/status/1370449655...   \n",
       "\n",
       "                                                  photos reply_to  retweet  \\\n",
       "3776                                                  []       []    False   \n",
       "11849                                                 []       []    False   \n",
       "12459                                                 []       []    False   \n",
       "9917                                                  []       []    False   \n",
       "1150                                                  []       []    False   \n",
       "201                                                   []       []    False   \n",
       "33939  ['https://pbs.twimg.com/media/FMPBgHWWUAoro-w....       []    False   \n",
       "21311                                                 []       []    False   \n",
       "31340                                                 []       []    False   \n",
       "33332                                                 []       []    False   \n",
       "\n",
       "       source                                              tweet  video  \n",
       "3776      NaN  @phillipcjackson turns out it doesn't need sec...      0  \n",
       "11849     NaN  Ability to stream YouTube &amp; Netflix when c...      0  \n",
       "12459     NaN  Much will likely go wrong on 1st mission. Also...      0  \n",
       "9917      NaN  This is why I‚Äôm not impressed when reporters w...      0  \n",
       "1150      NaN  While on the subject of AI risk, Our Final Inv...      0  \n",
       "201       NaN                      T minus five minutes to flame      0  \n",
       "33939     NaN                                            <image>      1  \n",
       "21311     NaN  Classifying all deaths as corona even if coron...      0  \n",
       "31340     NaN                                   And Mars  <link>      0  \n",
       "33332     NaN       Both do mining &amp; use blocks &amp; chains      0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_from_all_years.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bevor Text generiert wird, ist es interessant sich einmal anzusehen, wie der Datensatz aufgebaut ist. Bei strukturierten und numerischen Daten gibt es daf√ºr klare M√∂glichkeiten, die sich etabliert haben, wie etwa sich mit den Durchschnitten und Quantilen zu besch√§ftigen. Im Fall von Text ist das aber nicht direkt m√∂glich und auch nicht wirklich n√∂tig, weil es, wie sp√§ter beschrieben nur wenig direkte Evaluierung gibt. Es ist aber wichtig ein Gef√ºhl f√ºr den Datensatz zu erhalten um zu verstehen, ob die Generierungen gut oder schwach sind. Zuerst l√§sst sich die Herkunft der Daten bestimmen, aus welchem Jahr sie kommen. Wie zu erwarten ist hat Elon Musk mit voranschreitender Zeit mehr Tweets ver√∂ffentlicht. Der Datensatz reicht nur bis M√§rz 2022, weshalb es f√ºr das Jahr 2022 deutlich weniger Tweets sind, als im Juli 2022 zu erwarten w√§re. 2019 war das aktivste Jahr von Elon Musk von Elon Musk. 2020 war er dann vermutlich damit besch√§ftigt sich √ºber das erste Jahr zu freuen, in dem sein Unternehmen Tesla einen Gewinn abgeworfen hat und er twitterte entsprechend weniger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApgAAAKeCAYAAAABaGvUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAxOAAAMTgF/d4wjAAAhyklEQVR4nO3df7TteV3f99cbLg4k145IZoQwM16WA7qKGm0gqbaAREXNpMaUFuvqSIKsZMhaUessWifkZ9NUhyZMmi5NmEFZoxISihNNy6TmBxKwEsoY5KeGGX5cLhf5IaDBWykw8u4fZ19zvLk/9rnzPud7vuc+HmvtxTnfz97f8z6XO/c8z3d/93dXdwcAAKY8bOkBAAA4WgQmAACjBCYAAKMEJgAAowQmAACjBCYAAKOOLT3A+Vx11VV9zTXXLD0GAAAX8KEPfeiz3X3V+dYOZWBec801OX369NJjAABwAVX16xda8xQ5AACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAo44tPQAAXElO3Hbvvu7/5O037ev+YRuOYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBqq8CsqsdU1Vt33e6vqger6our6tqq+rmqeqCq3llVT9/1uAuuAQBwNG11Hczu/kSSrzn7eVW9MMkzuvuTVfXyJG/q7m+tqqcm+ZmqekJ3fy7J7RdZAwDgCLrcp8ifn+THNx8/J8lLk6S770vya0mescUaAABH0J4Ds6q+Psmjk7ymqh6T5BHd/ZFddzmZ5IaLrV3+uAAAHHaXcwTz+Ul+srsfnBqiqm6tqtNnb2fOnJnaNQAAB2xPgVlVx7PztPfLk989N/PBqnrsrrudSHLqYmvn7re77+ju687ejh8/vrfvAgCAQ2OvRzC/M8nbuvvf7tr26iQvSJLNC3ken+T1W6wBAHAEbfUq8l2en+Rl52z7wSQ/VVUPJPlskpt3vUr8YmsAABxBewrM7v7682z7aJJnXeD+F1wDAOBo8k4+AACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIw6tvQAALAXJ267d1/3f/L2m/Z1/3AlcAQTAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRAhMAgFECEwCAUQITAIBRx5YeAABYjxO33buv+z95+037un8OhiOYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACM2jowq+qqqvqRqnqgqt5RVa/YbH9iVb2xqu6vqvuq6sm7HnPBNQAAjqa9HMG8PUkneVJ3f1WSF26235nkru5+UpIXJ7l712MutgYAwBG0VWBW1e9P8vwkf6m7O0m6+yNVdW2SpyR5xeau9yS5vqpuvNja5DcAAMDhsu0RzC9L8skkL6qqX6qqX6iqb0xyfZIPd/eDSbKJz1NJbrjE2u9RVbdW1emztzNnzjzkbwwAgGVsG5jHknxpkl/p7qck+b4kr9psf8i6+47uvu7s7fjx4xO7BQBgAdsG4qkkn0/yD5Kku3+5qt6fneh8XFUd6+4Hq6qyc4TyVJJPXWQNAOBAnbjt3n3d/8nbb9rX/a/JVkcwu/vjSV6b5FuSpKqekOQJSX4xyVuS3Ly567OTnO7u93T3xy60Njc+AACHzV6e4n5Bkh+vqhdn52jmLd39oaq6JcndVfWi7By1fN6ux1xsDQCAI2jrwOzu9yV55nm2vzvJ113gMRdcAwDgaPJOPgAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIzaOjCr6mRVvbuq3rq5fedm+xOr6o1VdX9V3VdVT971mAuuAQBwNO31COZ3dvfXbG6v2my7M8ld3f2kJC9Ocveu+19sDQCAI+jYQ3lwVV2b5ClJnrXZdE+SH6mqG5N86kJr3f2eh/J1AZZ24rZ793X/J2+/aV/3D7Cf9noE8yer6h1V9eNVdU2S65N8uLsfTJLu7iSnktxwibXfo6purarTZ29nzpx5CN8SAABL2ktgPr27vzrJf5Lk40l+YmqI7r6ju687ezt+/PjUrgEAOGBbP0Xe3ac2//u5qvpfk9yf5INJHldVx7r7waqq7ByhPJWdp8gvtAYAwBG11RHMqvr9VfVFuzZ9V5Jf7u6PJXlLkps325+d5HR3v+diayOTAwBwKG17BPNLktxTVQ9PUknel+S5m7VbktxdVS/KzlHL5+163MXWAAA4grYKzO5+X5KvvcDau5N83V7XAAA4mryTDwAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjji09AAAH78Rt9+7r/k/eftO+7h843BzBBABglMAEAGCUwAQAYJRzMLmiOQ8NAOY5ggkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwKg9B2ZVPa+quqq+Y/P5tVX1c1X1QFW9s6qevuu+F1wDAOBo2lNgVtWJJH82yZt2bb49yZu6+4lJnpfklVX1iC3WAAA4grYOzKp6WJIfS/K9ST6za+k5SV6aJN19X5JfS/KMLdYAADiC9nIE89Ykv9jd/+bshqp6TJJHdPdHdt3vZJIbLrZ2+eMCAHDYHdvmTlX1lUmenWRfzqGsqluzE7BJkquvvno/vgwAAAdg2yOYT0tyIskDVXUyyX+a5K7sPAX+YFU9dtd9TyQ51d2fuNDauTvv7ju6+7qzt+PHj+/1+wAA4JDYKjC7++939+O6+0R3n8jOi3z+XHf//SSvTvKCJKmqpyZ5fJLXbx56sTUAAI6grZ4iv4QfTPJTVfVAks8mubm7P7fFGgAAR9BlBWZ3f8Oujz+a5FkXuN8F1wAAOJq8kw8AAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAowQmAACjBCYAAKMEJgAAo44tPQBwZTpx2737uv+Tt9+0r/sH4MIcwQQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGDU1oFZVf+8qt5eVW+tql+oqq/dbH9iVb2xqu6vqvuq6sm7HnPBNQAAjqa9HMF8Tnd/dXd/TZI7kty92X5nkru6+0lJXrxr+6XWAAA4grYOzO7+zV2fXp2kq+raJE9J8orN9nuSXF9VN15s7SFPDQDAoXVsL3euqp9M8szNp388yfVJPtzdDyZJd3dVnUpyQ5J/d5G195yz31uT3Hr286uvvvryvhsAABa3pxf5dPdzu/v6JH85O095j+juO7r7urO348ePT+0aAIADdlmvIu/un8jOkczTSR5XVceSpKoqO0coTyX54EXWAAA4orYKzKr6oqr6g7s+/44kn0jysSRvSXLzZunZSU5393u6+4JrQ7MDAHAIbXsO5tVJXl1Vj0ry+SS/nuRPbM6rvCXJ3VX1oiSfSvK8XY+72BoAAEfQVoHZ3R9I8kcusPbuJF+31zUAAI4m7+QDAMAogQkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwCiBCQDAKIEJAMAogQkAwKhjSw/Aup247d593f/J22/a1/0DAPMcwQQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGCUwAQAYJTABABglMAEAGDUVoFZVY+sqp+tqvur6m1V9S+q6sbN2rVV9XNV9UBVvbOqnr7rcRdcAwDgaNrLEcy7knx5d/+hJP8kyY9ttt+e5E3d/cQkz0vyyqp6xBZrAAAcQVsFZnf/f939T7u7N5velOTE5uPnJHnp5n73Jfm1JM/YYg0AgCPocs/B/P4k/6SqHpPkEd39kV1rJ5PccLG1c3dWVbdW1emztzNnzlzmWAAALG3PgVlVL0pyY5K/ODVEd9/R3dedvR0/fnxq1wAAHLA9BWZVvTDJf5nk27r7t7v7E0kerKrH7rrbiSSnLrb20EYGAOAw2zowq+rWJN+V5Ju7+zd3Lb06yQs293lqkscnef0WawAAHEHHtrlTVV2X5CVJ3pfkdVWVJJ/p7j+a5AeT/FRVPZDks0lu7u7PbR56sTUAAI6grQKzu08nqQusfTTJs/a6BgDA0eSdfAAAGCUwAQAYJTABABglMAEAGLXVi3yAw+nEbffu275P3n7Tvu0bgKPNEUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABGHVt6AAAALu3Ebffu6/5P3n7T2L4cwQQAYJTABABg1FaBWVX/W1WdrKquqq/Ztf2JVfXGqrq/qu6rqidvswYAwNG17RHMn07ynyf5wDnb70xyV3c/KcmLk9y95RoAAEfUVoHZ3W/o7tO7t1XVtUmekuQVm033JLm+qm682NrM2AAAHFYP5RzM65N8uLsfTJLu7iSnktxwiTUAAI6wQ/Ein6q6tapOn72dOXNm6ZEAALhMDyUwP5jkcVV1LEmqqrJzhPLUJdb+A919R3dfd/Z2/PjxhzAWAABLuuzA7O6PJXlLkps3m56d5HR3v+diaw9lWAAADr+t3smnqu5MclOSxyb5Z1X1W919Y5JbktxdVS9K8qkkz9v1sIutAQBwRG0VmN19ywW2vzvJ1+11DQCAo+tQvMgHAICjQ2ACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMEpgAgAwSmACADBKYAIAMOrY0gOQnLjt3n3b98nbb9q3fQMAnI8jmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACMEpgAAIwSmAAAjBKYAACM2vfArKonVtUbq+r+qrqvqp68318TAIDlHMQRzDuT3NXdT0ry4iR3H8DXBABgIfsamFV1bZKnJHnFZtM9Sa6vqhv38+sCALCc6u7923nVH07yyu7+8l3b3pzktu7++V3bbk1y666HPjbJR/ZtsOR4kjP7uP/9tObZE/Mvbc3zr3n2xPxLWvPsifmXtObZk/2f/5ruvup8C8f28YturbvvSHLHQX29qjrd3dcd1NebtObZE/Mvbc3zr3n2xPxLWvPsifmXtObZk2Xn3+9zMD+Y5HFVdSxJqqqS3JDk1D5/XQAAFrKvgdndH0vyliQ3bzY9O8np7n7Pfn5dAACWcxBPkd+S5O6qelGSTyV53gF8zUs5sKfj98GaZ0/Mv7Q1z7/m2RPzL2nNsyfmX9KaZ08WnH9fX+QDAMCVxzv5AAAwSmACADBKYAIAMEpgAgAwSmACADDqULyTz36rqocneUZ2LvKe7Fzo/fXd/TvLTfXQVNVjuvsTS8+xjap6WHd//pxtj+7u31hqpsuxecOAr0ryvu7+d0vPs1dV9T91919Zeo7Ltca/M2dV1VcleWqSt3f3Ly09z8VU1Vd29zuXnuOhqKqvSPLJ7v7Y5uP/LMk7u/v/WXi0rVTVVUm+LcmJJA8meVd3v27Rofagqh6d5E/l9/7M/dnu/uRyUz00VfWHuvttS89xKVX1qOy8feOpc7Y/ubvfdZCzHPkjmFX1tCQnk/xQdv6D/bYkP5zkZFU9fcHRHqpfXnqAS6mqp1TV+5N8uqp+pqqu2bX82qXm2lZV/bGq+kRVfbyqnpHkjUlemeS9m88Prar6vnNvSf78ro8Ptar6/l0fP6Gq3pXk16rq/ZtYO9Sq6rVVde3m4+ck+bkk35rkp6vqlkWHu7S3V9XbNn9XvnjpYfaqqv77JK9P8ktVdXOSf57kW5L877v/Xh1WVfXMJPcn+R+T3J7kTyb50ap6c1U9ftHhtlBVz07yb5M8K8mjNrdvSfIrm7W1+j+XHuBSqupZST6c5B1V9ZaqunHX8k8d9DxXwhHMH03yp849alBVT03y8uwckTqUqurbL7L8yAMb5PL9nSR/Icmbkvx3Sd5QVd/U3R9KUksOtqUfTvKNSb4oyT1JntPdP19VfyTJS5I8bcHZLuWOJPcm2X3E4KokX5tkDRe//dNJ/u7m4x9K8ve6+0c3P6DuSPLNi022nWs272SWJD+Q5Ou7+wObYPtXSe5cbLJLe1eSv5Hk+Ul+qKpek+THuvtfLjvW1v5Mkq9Icjw7ofOV3f3+qvoD2fmz/7sXfuih8JIk39TdD2x+Tn1vd39zVf3Z7Pw8+45Fp7u0/znJH+3uk7s3VtUTkvxf2fm39FC6yC/flZ2/T4fd30zy9CTvSPI9Sf5lVf2JzTMSB/4z90oIzEee7ymp7r5v8zTEYfYz2flN/Hx/Mb7wgGe5HMe7+97Nx3+lqt6d5Oer6puyjsj5gu5+a5JU1W92988nSXe/uaoO+z82z8pOIL+su1+TJFX1Dd19GN5Ja6/+4+7+riTp7nuqag1P819VVQ/fnIZT3f2BJOnuT1bVYf/l6nPdfU+Se6rq+uzE/p2bU41e3t1/Y9nxLukzm1MpfqOqPt7d70+S7v54VX1u4dm28bDufiD53Z9TT958/LKqeuGyo23l4efGZZJsIv+wN8dLkvyDnP/n0yMOeJbL8Yjufvvm4x+vqpNJXlNVfzIL/Mw97P9nT3hvVf3VJC89e0Rh89TVn0/y/kUnu7QHknzP+f5jraoPHvw4e/b7dp9/2d2v2PwD/9rsHE077HafQvLqc9YefpCD7NXmSOs3J/mRzVG/7886ov6sL6qq/yI7v1yd+w/7YQ+0JPmHSV5VVbdl52nxv5SdH1zfluR9i062B939wewcFfmbVfWN2Tkqcth9pqpuSvLoJF1V39ndr9o89byG8+7PVNUzu/t1VfVfJfnYJR9xuNxXVS9P8tIkH9hs+9IkL0hyqM8/TvKrSX64u9997sLmwMhh98iquqq7P5Mk3f3aqvrTSf6PJF9w0MNcCYH53Oycx/LeXb89PZidYPjuxabazk8k+QPZOYf0XC892FEuyy8m+eNJXnN2w+Yf+k7yisWm2t6/qar/qLs/1d1/8ezGqvqyJJ9acK6tdPenkjx3E5ivz865UGtxKsmtm48/WlWP7+4PbX45/OyCc22lu//65ny/1yX5kuz8W/s/ZCc8D/tR5PP++Xb3a7OCc6eTfF+Su5J8PjvnL95WVT+R5EyS5yw52JZ+IMk/3jyl/+HsfA+pqsdm55eUw+75SV6YnVPQzr7I5wNJfjrJ31pqqC39nVw4xP7yQQ5ymf5xkm9I8s/Obuju11fVdyf5sYMe5op6L/KzJ6yv+ZVsLG/zi8ojuvvTS8+yrar6kiR/uLv/6dKzPBSbp2mv6u7fXnqWbVXVFyY5ttZXwB8FVfWYJL9x7tUsDrNa0ZVC4HyO/KvId+vuT+6Oy80/Oqu05tmTdc/f3Q8m+X1Lz7EX3f3Rs3G58j/738m6jsSmu39rd1yu+c9/rbN39ye6+/Nrmv98cbmm+avqP+iL2rl80aG35tmTwzP/FRWY53HoL/VzEWuePTH/ktY8e2L+Ja159sT8+27Nl6db8+zJ4Zv/yJ+DueZL/ax59sT8S1rz7In5l7Tm2RPzHwJrvjzdmmdPDtn8Rz4ws+5L/ax59sT8S1rz7In5l7Tm2RPzL23Nl6db8+zJIZv/SgjMNV/qZ82zJ+Zf0ppnT8y/pDXPnph/aWu+PN2aZ08O2fxXwjmYZy/1cz6H/VI/a549Mf+S1jx7Yv4lrXn2xPxLO3t5ut/V3a/KzmV+HrfIRNtb8+zJIZv/irpMEQAA++9KeIr87LXznpF/f9HXU0lev7nkyaG25tkT8y9pzbMn5l/SmmdPzL+0Nc+/5tmTwzX/kT+CWVVPS/LKJB/Kv3/bqhNJ/mCS/7a737DQaJe05tkT8y9pzbMn5l/SmmdPzL+0Nc+/5tmTQzh/dx/pW5K3J3nKebY/Nck7lp7vqM5ufrObf53zr3l28y9/W/P8a579MM5/JbzI55Hd/Uvnbuzu+3L4XxW25tkT8y9pzbMn5l/SmmdPzL+0Nc+/5tmTQzb/lRCY762qv1pV157dUFXXVtVfS/L+BefaxppnT8y/pDXPnph/SWuePTH/0tY8/5pnTw7Z/FdCYD43O+cgvLeqPl1Vn07y3iRfmuS7lxxsC2uePTH/ktY8e2L+Ja159sT8S1vz/GuePTlk8x/5F/nsVlVfnCTd/cmlZ9mrNc+emH9Ja549Mf+S1jx7Yv6lrXn+Nc+eHI75j/wRzKr6sqp6XVW9LzsXG/3tXWv/ernJLm3NsyfmX9KaZ0/Mv6Q1z56Yf2lrnn/NsyeHb/4jH5hJ/l6Sn07yX2fn3RFeW1Vn38/1kYtNtZ01z56Yf0lrnj0x/5LWPHti/qWtef41z54ctvmXfln9Abxs/5fP+fxFSd6c5Ookb1l6vqM6u/nNbv51zr/m2c2//G3N86959sM4/5XwTj6P2v1Jd/9QVX02O2/+/oXnf8ihsebZE/Mvac2zJ+Zf0ppnT8y/tDXPv+bZk0M2/5XwFPmvVtW37t7Q3X87O1e7/7JlRtrammdPzL+kNc+emH9Ja549Mf/S1jz/mmdPDtn8R/5V5FV1VZJ092fOs/b47v7QwU+1nTXPnph/SWuePTH/ktY8e2L+pa15/jXPnhy++Y98YAIAcLCuhKfIAQA4QAITAIBRAhMAgFECE2BIVX28qk5c4j5/varWcNFmgMsmMAEO1l/LOt4VBOCyCUyAy1RV315Vv1pVb6+q/2XX9r9dVfdV1Vur6g1V9eWb7S/d3OUXNmvXVtUXVtXLqurNm/3cVVVfsMg3BDDEZYoALkNVXZvkV5M8rbt/par+XJI7kzwhyf/b3b++ud9/k+TPdPe3bj7vJI/u7t/cfH5Xkv+7u3+yqirJy5K8u7v/1oF/UwBDBCbAZaiqb0/yA939zM3nD0/y20m+PMnXJ/ne7Lw928OSfHF3P3Zzv3MD82NJPprkdza7flSSf9XdtxzcdwMw60p4L3KAg3D2t/UbkvxIkqd293ur6quTvOEij6skz+7u+/d7QICD4hxMgMvzr5N8dVV9xebz70nyBUl+I8nnknx485T3Xzjncb+V5Opdn/9skh+sqmNJUlWPrqob93NwgP0mMAEuw+Ycy+9J8jNV9bYkT0zyiewE5D9K8q4k9yU5dc5DX5LkX5x9kU+SH0jy6SRvraq3J3ltkhMH8k0A7BPnYAIAMMoRTAAARglMAABGCUwAAEYJTAAARglMAABGCUwAAEYJTAAARglMAABG/f/bh/55qtAGCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10), dpi=80)\n",
    "tweets_from_all_years.groupby(pd.Grouper(key = 'date',freq='Y')).size().plot(kind='bar')\n",
    "plt.xticks(range(13),['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020', '2021','2022'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zur Analyse des Textes der Tweets l√§sst sich ein tool wie Rake verwenden. Rake extrahiert die wichtigsten Keywords aus Texten. Dabei wird zuerst eine Stopwordliste angewendet, also eine Liste mit W√∂rtern die ignoriert werden sollen wie 'ist' oder 'das', weil sie sehr oft vorkommen aber nicht relevant f√ºr den Inhalt sind. Danach verwendet Rake verschiedene Methoden um die Wichtigkeit eines Wortes festzustellen, indem zum Beispiel die Co-Occurences mit anderen wichtigen Worten festgestellt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.0, 'üñ§üñ§üñ§üñ§ üöòüöòüöòüöò üñ§üñ§üñ§üñ§'),\n",
       " (9.0, '‚ô•Ô∏è‚ô•Ô∏èüáÆüá∏üáÆüá∏ √≠sland üáÆüá∏üáÆüá∏‚ô•Ô∏è‚ô•Ô∏è'),\n",
       " (9.0, 'vigorously opposed subpoena'),\n",
       " (9.0, 'tcp packet walks'),\n",
       " (9.0, 'tallakt various forms'),\n",
       " (9.0, 'spinal cord transplant'),\n",
       " (9.0, 'spiked choker machined'),\n",
       " (9.0, 'some1gg transpiration cooling'),\n",
       " (9.0, 'siberian permafrost melting'),\n",
       " (9.0, 'shortseller enrichment commission')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_buzzwords = Rake(max_length=3)\n",
    "tweet_buzzwords.extract_keywords_from_sentences(tweets_from_all_years['tweet'].to_list())\n",
    "tweet_buzzwords.get_ranked_phrases_with_scores()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Ergebnisse der Keyword Extraktion sind allerdings nicht sehr aussagegr√§ftig, wenn davon abgesehen wird, dass Musk scheinbar eine gro√üe Liebe f√ºr Island hat. Das ergibt aber auch durchaus Sinn, wenn bedacht wird, dass Rake eigentlich f√ºr gr√∂√üere Texte entwickelt wurde. [(Vgl. Rose 2010 et. al.)](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents) Eine deutlich interessantere Metrik ist in diesem Fall aber die Wordfrequenz, mit den angewendeten Stopwords. Also das einfache Z√§hlen der W√∂rter und dann einem Entfernen aller Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kw_dist =  tweet_buzzwords.get_word_frequency_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## remove technical words and tokens\n",
    "del(kw_dist['amp'])\n",
    "del(kw_dist['link'])\n",
    "del(kw_dist['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n = 25\n",
    "kw_dist_top = {k:v for k,v in kw_dist.items() if v >= min(sorted(kw_dist.values(), reverse=True)[:n])}\n",
    "kw_dist_top_sorted = dict(sorted(kw_dist_top.items(), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10), dpi= 80)\n",
    "lables = []\n",
    "for i, w in enumerate(kw_dist_top_sorted):\n",
    "    plt.bar(x = i,height= kw_dist[w])\n",
    "plt.xticks(range(n),kw_dist_top_sorted.keys(), rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In gewisser Weise sind diese Ergebnisse dann doch √ºberraschen, denn es ist nicht zu erwarten gewesen, dass Musk 'Tesla' und 'model' (von Model S oder Model 3, Modellbezeichungen der Tesla-Fahrzeuge) mehr als doppelt so oft vorkommen, wie die n√§chsten Top W√∂rter. Sonst wird sehr oft Launch, also SpaceX Launches erw√§hnt und allgemein viel √ºber 'cars' getwittert, was aber zu erwarten ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Erstellung der Datens√§tze und Entwicklung des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zur Generierung von Text gibt es viele M√∂glichkeiten. Die klassische Methode sind Markov-Ketten, in denen immer das n√§chste Wort auf Basis des vorherigen Wortes vorhergesagt wird. Der moderne Ansatz sind auf neuronalen Netzen aufbauende Modelle. Einfache Perceptrons bieten aber nur wenige bis keine M√∂glichkeiten zusammenh√§ngende S√§tze zu verarbeiten. Stattdessen wurden Architekturen wie Recurrent Neural Networks entwickelt, in denen Neuronen auch mit Ausgaben folgender Neuronen gef√ºttert werden. Das LSTM speichert Eingaben vorheriger Eingaben und kann so mit sequentiellen Daten arbeiten. Der heutige Standard sind aber sogenannte Transformer. Ihre Grundlage ist der Attention-Mechanismus. Attention beruht auf Lookup-Tabellen, die im Netzwerk anlernbar sind. Beim Vorhersagen eines Elements in einer Sequenz kann also auch gelernt werden, welche Elemente davor und danach vorkommen. Das Training ist daf√ºr sehr aufw√§ndigt und ben√§tigt einen sehr gro√üen Korpus. Ein Modell, das mit einem solchen Korpus trainiert wurde ist GPT2. Der Korpus besteht aus den Texten von 8 Millionen Websites, auf die von der Internet-Plattform Reddit verlinkt wird. Weil die generierten Texte dadurch sehr gut Texte widerspiegeln, die im Internet zu finden sind, wird GPT-2 sehr oft f√ºr die Generierung von Texten, die Sprache im Intenet imitieren sollen genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Elon Musk is a ersatz social conservative. The internet does not represent any individual's political viewpoints. You might call him a fascist or a dictator, but he can't be taken into account by anyone. It is impossible to know if he\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"Elon Musk is a \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Modell ist aber die Sprache von Elon Musk nicht gut repr√§sentiert. Um das zu verbessern wird auf Transfer-Learning zur√ºckgegriffen. Beim Transfer Learning wird statt ein neues Modell zu trainieren ein existierendes Modell wie GPT-2 mit den spezifischen Daten trainiert. Die Bibliothek `transformers` bietet daf√ºr eine Reihe von existierienden Modellen, darunter auch GTP-2 an.\n",
    "Sprachemodelle k√∂nnen nicht mit den Rohen sprachdaten trainiert werden. Sie werden mit einer aneinanderreihung von Tokens, also numerischen Werten, die die einzelnen W√∂rter repr√§sentieren trainiert. GPT-2 bietet bereits einen passenden Tokenizer, der auf Texte mit Elon Musks Tweets angepasst werden muss. Weil das Modell immer ein Prompt braucht im Text zu generieren, wird ein `BOS_TOKEN` hinzugef√ºgt, der als Prompt auch im Training vor jedem Tweet eingef√ºgt wird. So lernt das Modell, dass jedem Prompt, ein Tweet von Elon Musk folgt. Es gibt auch einen End of Sequence Token, damit soll unter anderem gelernt werden, keine zu langen Texte zu generieren. In der Praxis funktioniert dies aber nur bedingt zuverl√§ssig. Der `IMAGE_TOKEN` und der `LINK_TOKEN` sollen daf√ºr sorgen, dass diese Teile des textes nicht aus anderne Tokens zusammengesetzt werden sondern immer am St√ºck vorhergesagt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<|elontext|>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "PAD_TOKEN = \"<|pad|>\"\n",
    "IMAGE_TOKEN = \"<image>\"\n",
    "LINK_TOKEN = \"<link>\"\n",
    "MAX_TOKENS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\",\n",
    "    bos_token=BOS_TOKEN,\n",
    "    eos_token=EOS_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    max_length=MAX_TOKENS,\n",
    "    is_split_into_words=True,\n",
    ")\n",
    "tokenizer.add_tokens([LINK_TOKEN, IMAGE_TOKEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Tokenizer werden auch gespeichert, damit sie sp√§ter zur Weiterverwendung verf√ºgbar sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained('./musktokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Neben GPT-2 wird au√üerdem noch das Modell 'distil-gpt2' genutzt. Das ist eine kleinere Version von 'GPT-2' und nutzt etwa die H√§lfte der Neuronen bzw. Parameter. Beide Modelle sollen verglichen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\",\n",
    "                                          bos_token=BOS_TOKEN,\n",
    "                                          eos_token=EOS_TOKEN,\n",
    "                                          pad_token=PAD_TOKEN,\n",
    "                                          max_length=MAX_TOKENS,\n",
    "                                          is_split_into_words=True,\n",
    "                                          )\n",
    "distil_tokenizer.add_tokens([LINK_TOKEN, IMAGE_TOKEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um sicher zu gehen, dass mit korrekten Daten gelernt wird, werden die Tokenizer einmal getestet. Daf√ºr wird ein Text encodiert und decodiert. Dann wird gepr√ºft, ob der noch lesbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "some_tweets = tweets_from_all_years.sample(n=10, random_state=30)\n",
    "encoded = tokenizer(some_tweets['tweet'].to_list()[0], padding=True, max_length=MAX_TOKENS, pad_to_max_length=True,)\n",
    "decoded = tokenizer.decode(encoded['input_ids'])\n",
    "some_tokens=[]\n",
    "for i in some_tweets['tweet']:\n",
    "    some_tokens.append(' '.join(i.split(' ')[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoded = tokenizer(some_tweets['tweet'].to_list()[0], padding=True, max_length=MAX_TOKENS, pad_to_max_length=True,)\n",
    "decoded = tokenizer.decode(encoded['input_ids'])\n",
    "some_distil_tokens=[]\n",
    "for i in some_tweets['tweet']:\n",
    "    some_distil_tokens.append(' '.join(i.split(' ')[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tesla will make some merch',\n",
       " '0 to 155mph trap speed',\n",
       " 'Order at  <link>',\n",
       " '5 minutes from launch. Looks',\n",
       " 'Spacecraft arrives at Port of',\n",
       " 'Space Station tracking spaceship docking',\n",
       " \"Hope we're not just the\",\n",
       " 'Truth is a metaphorical concept',\n",
       " ' <image>',\n",
       " 'These are production design, unlike']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Erstellung von Datens√§tzen, die mit Tensorflow und dem Modell kompatibel sind ist eine gr√∂√üere Herausforderung. Daf√ºr wird die `transformers` zugeh√∂rige Bibliothek `datasets` verwendet. Au√üerdem wird ein Train-und Test-Split erstellt. Das Test Split wird zum Hyperparameter-Tuning verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Set tweets to subset or to full dataset\n",
    "#tweet_ds = some_tweets\n",
    "import datasets\n",
    "tweet_ds = tweets_from_all_years\n",
    "# Damit sich der Datensatz nachher sicher in das Tensorflow Datenformat konvertieren l√§sst muss mit dem Datenset-Format der transformers library erstellt werden\n",
    "tweets_ds = datasets.Dataset.from_pandas(tweet_ds[['tweet']])\n",
    "\n",
    "tweets_ds = tweets_ds.train_test_split(test_size=0.2)\n",
    "MAX_TOKENS = max([len(tokenizer.encode(tweet, add_special_tokens=True)) for tweet in tweet_ds['tweet']])+2\n",
    "DISTIL_MAX_TOKENS = max([len(distil_tokenizer.encode(tweet, add_special_tokens=True)) for tweet in tweet_ds['tweet']])+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', '__index_level_0__'],\n",
       "    num_rows: 3912\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', '__index_level_0__'],\n",
       "    num_rows: 978\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die `prepare_text` Funktion wird sp√§ter mit einer `map` Funktion verwendet um die Texte in token-sequenzen umzuwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## mit anpassungen √ºbernommen aus https://data-dive.com/finetune-german-gpt2-on-tpu-transformers-tensorflow-for-text-generation-of-reviews\n",
    "def prepare_text(tweets:list, prep_tokenizer, prep_MAX_TOKENS):\n",
    "    # Einf√ºgen der Prompts vor jeden Tweet\n",
    "    text = [BOS_TOKEN + tweet + EOS_TOKEN for tweet in tweets['tweet']]\n",
    "\n",
    "    tokenized = prep_tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,  # Only adds pad not eos and bos\n",
    "        max_length=prep_MAX_TOKENS,\n",
    "        truncation=True,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_tweets_ds = tweets_ds.map(\n",
    "    lambda x: prepare_text(x, distil_tokenizer,DISTIL_MAX_TOKENS),\n",
    "    batched=True,\n",
    "    #num_proc=4,\n",
    "    # urspr√ºnglich spalten entfernen\n",
    "    remove_columns=['tweet','__index_level_0__'],\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_ds = tweets_ds.map(\n",
    "    lambda x: prepare_text(x, tokenizer, MAX_TOKENS),\n",
    "    batched=True,\n",
    "    #num_proc=4,\n",
    "    remove_columns=['tweet','__index_level_0__'],\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der fertige Text wird zum Test nochmal dekodiert. Nun sind auch Padding Tokens vorhanden, um alle Sequenzen auf die gleiche L√§nge, und damit in ein f√ºr das Modell zu verarbeitende Format zu bringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|elontext|>Am getting lots of questions about the big Supercharger announcement. Aiming to do that the week after next.<|endoftext|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tweets_ds['train']:\n",
    "    print(tokenizer.decode(i['input_ids']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Datenset muss in das von Tensorflow Datenformat konvertiert werden. Daf√ºr bietet `datasets` eine vorgefertigte Funktion und es muss lediglich eine funktion drum herum geschrieben werden, die das Schema an das Modell anpasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "DataCollators sind eine Funktion von `datasets` um weitere funktionen zu der Konvertierungs-Pipeline hinzuzuf√ºgen. In diesem Fall ist er nur ein Hilfswerkzeug zur generierung der Datens√§tze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = tweets_ds['train'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test = tweets_ds['test'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_train = distil_tweets_ds['train'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "distil_test = distil_tweets_ds['test'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "F√ºr das Training werden einige Hyperparameter ben√∂tigt, die nicht manuell angepasst werden. Zudem wird der Datensatz in Batches unterteilt, damit Stochastic Gradient verwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train)\n",
    "DISTIL_BUFFER_SIZE = len(distil_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_train = distil_train.shuffle(len(distil_train))\n",
    "train = train.shuffle(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Modelle von `transformers` sind mit Tensorflow kompatibel und lassen sich √ºber die Bibliothek einfach laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "distil_model = TFGPT2LMHeadModel.from_pretrained(\n",
    "    \"distilgpt2\",\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "\n",
    "# Weil die anzahl der Standard Tokens im Tokenizer angepasst wurde, m√ºssen auch die Gr√∂√üen der ersten Layer angepasst werden.\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "distil_model.resize_token_embeddings(len(distil_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der am meisten genutzte Optimizer ist Adam. Dieser wird auch in GPT-2 und dementprechen duach hier verwendet. Die Parameter sind die, die auch im Grundtraining von Tensorflow verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124442880 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,442,880\n",
      "Trainable params: 124,442,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 81915648  \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,915,648\n",
      "Trainable params: 81,915,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distil_optimizer = AdamWeightDecay(learning_rate=1e-6, weight_decay_rate=0.01)\n",
    "distil_model.compile(optimizer=distil_optimizer)\n",
    "distil_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie zu sehen, hat das `distil_model` deutlich weniger Parameter als das normale Modell. In diesem Fall sind es aber nicht wie angegeben die H√§flte sondern etwas mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der `fit` Funktion wird das Training gestartet. Bei GPT-2 dauert es etwa 1-2h auf einem MacBook Pro mit Intel Core i9 ohne GPU Beschleunigung. Mit der Hardware Beschleunigung einer GTX 1070 l√§sst sich diese Zeit auf wenige Minuten k√ºrzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "244/244 [==============================] - 66s 203ms/step - loss: 2.3092\n",
      "Epoch 2/6\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 1.2153\n",
      "Epoch 3/6\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 1.0298\n",
      "Epoch 4/6\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 1.0258\n",
      "Epoch 5/6\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.9704\n",
      "Epoch 6/6\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.9624\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(\n",
    "    train.repeat(),\n",
    "    epochs=6,\n",
    "    steps_per_epoch=BUFFER_SIZE / BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Modell l√§sst sich speichern, die Funktion sind aber auskommentiert, damit nicht aus versehen ein exisiterendes Modell √ºberschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"./MUSK_GPT_UNOPTIMIZED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Training von GPT-2 dauert mit dem MacBook unter 15 Minuten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'labels': TensorSpec(shape=(4, None), dtype=tf.int64, name=None), 'input_ids': TensorSpec(shape=(4, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(4, None), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "244/244 [==============================] - 39s 161ms/step - loss: 1.8267 - val_loss: 1.7123\n",
      "Epoch 2/6\n",
      "244/244 [==============================] - 39s 159ms/step - loss: 1.7179 - val_loss: 1.5952\n",
      "Epoch 3/6\n",
      "244/244 [==============================] - 39s 159ms/step - loss: 1.5829 - val_loss: 1.5181\n",
      "Epoch 4/6\n",
      "244/244 [==============================] - 39s 159ms/step - loss: 1.5108 - val_loss: 1.4564\n",
      "Epoch 5/6\n",
      "244/244 [==============================] - 40s 162ms/step - loss: 1.4772 - val_loss: 1.3998\n",
      "Epoch 6/6\n",
      "244/244 [==============================] - 39s 160ms/step - loss: 1.4880 - val_loss: 1.3570\n"
     ]
    }
   ],
   "source": [
    "distil_model_hist = distil_model.fit(\n",
    "    distil_train.repeat(),\n",
    "    epochs=6,\n",
    "    steps_per_epoch= DISTIL_BUFFER_SIZE / BATCH_SIZE,\n",
    "    validation_data=distil_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#distil_model.save_pretrained(\"./MUSK_DISTIL_GPT_UNOPTIMIZED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameter Optimierung\n",
    "Hyperparameter Optimierung hat bei generativen Sprachemodellen nur einen geringen Einfluss. Ein Modell ist aufgrund schlechterer Metriken, in der Wahrnehmung eines Menschen zwangsl√§ufig schlechter. Im Voraus l√§sst sich dazu allerdings kein Beurteilung machen. Sie wird aber trotzdem durchgef√ºhrt, weil sie f√ºr Machine Learning im allgemeinen obligatorisch ist. In diesem Fall wird das Framework KerasTrainer verwendet. Die Parameter die optimiert werden sollen sind die Batch Size, die Learning Rate, der Weight Decay und die anzahl der Epochen. Aufgrund des hohen Zeitaufwandes und des hohen Energieverbrauchs des Hyperparametertunings, gibt es nur einen sehr eng begrenzten Suchbereich. Dieser wird auch nicht erweitert, wenn die optimalen Werte ganz au√üen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#tunable parameters\n",
    "batch_size=16\n",
    "lr=2e-5\n",
    "num_train_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#https://wandb.ai/amogkam/transformers/reports/Hyperparameter-Optimization-for-Huggingface-Transformers--VmlldzoyMTc2ODI\n",
    "class Musk_Model(kt.HyperModel):\n",
    "\n",
    "    def __init__(self, huggingface_model='gpt2', name=None, tunable=True):\n",
    "        self.huggingface_model = huggingface_model\n",
    "        super().__init__(name, tunable)\n",
    "\n",
    "    def build(self, hp: kt.HyperParameters):\n",
    "        self.BATCH_SIZE = hp.Choice('batch_size',[4,8,16,32])\n",
    "        model = TFGPT2LMHeadModel.from_pretrained(\n",
    "            self.huggingface_model,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "        )\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        optimizer = AdamWeightDecay(learning_rate=hp.Choice('learning_rate', [2e-5, 3e-5, 5e-5, 7e-5]), weight_decay_rate=hp.Choice('weight_decay_rate',[0.0,0.01, 0.001,0.1]))\n",
    "        model.compile(optimizer=optimizer)\n",
    "        return model\n",
    "    def fit(self, hp: kt.HyperParameters, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            train.repeat(),\n",
    "            batch_size= self.BATCH_SIZE,\n",
    "            epochs=hp.Int('epochs',min_value=2, max_value=8),\n",
    "            steps_per_epoch=BUFFER_SIZE / self.BATCH_SIZE,\n",
    "            validation_data=test,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Als Optimierungsalgorithmus wird Bayesche Optimierung genutzt. Dies ist eine gute Balance zwischen Zeitaufwand, Entwicklungsaufwand und Qualit√§t der Ergebnisse. Mit `val_loss` als objective wird der Validierungsdatensatz als Zielwert verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "batch_size (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 8, 16, 32], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 2e-05, 'conditions': [], 'values': [2e-05, 3e-05, 5e-05, 7e-05], 'ordered': True}\n",
      "weight_decay_rate (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.01, 0.001, 0.1], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel=Musk_Model(),\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=8,\n",
    "    overwrite=True,\n",
    "    directory=\"hyper-opt/\",\n",
    "    project_name=\"tune_tweet_generation\",\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 04m 20s]\n",
      "val_loss: 0.9074983596801758\n",
      "\n",
      "Best val_loss So Far: 0.8868565559387207\n",
      "Total elapsed time: 00h 44m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search()\n",
    "best_hp: kt.engine.hyperparameters.HyperParameters = tuner.get_best_hyperparameters()[0]\n",
    "best_hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hyper_model = Musk_Model()\n",
    "optimized_model = hyper_model.build(best_hp)\n",
    "optimized_hist = hyper_model.fit(best_hp,optimized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#optimized_model.save_pretrained(\"./MUSK_GPT_OPTIMIZED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier l√§sst sich der Loss √ºber den Zeitraum aller Iterationen beim optimiertenModell betrachten. Der Validierungs-Datensatz wird dabei immer nur ein Wenig besser, w√§hrend das Modell im Trainingsdatensatz schnell besser und am Ende ein wenig schlechter wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(optimized_hist.history['loss'], label=\"Loss √ºber die Epochen\")\n",
    "plt.plot(optimized_hist.history['val_loss'], label=\"Validierungs-Loss √ºber die Epochen\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch das Tuning der Hyperparameter wird mit \"distilgpt2\" wiederholt. Die ben√∂tigte Zeit ist hiet deutlich geringer. Zur Vergleichbarkeit werden aber auch hier die gleichen Strategien angewendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "distil_tuner = kt.BayesianOptimization(\n",
    "    hypermodel=Musk_Model(huggingface_model='distilgpt2'),\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=8,\n",
    "    overwrite=True,\n",
    "    directory=\"hyper-opt/\",\n",
    "    project_name=\"tune_distil_tweet_generation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 02m 30s]\n",
      "val_loss: 0.9383436441421509\n",
      "\n",
      "Best val_loss So Far: 0.9278596639633179\n",
      "Total elapsed time: 00h 28m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "distil_tuner.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4,\n",
       " 'learning_rate': 7e-05,\n",
       " 'weight_decay_rate': 0.1,\n",
       " 'epochs': 8}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_d_hp: kt.engine.hyperparameters.HyperParameters = distil_tuner.get_best_hyperparameters()[0]\n",
    "best_d_hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "244/244 [==============================] - 79s 261ms/step - loss: 1.7410 - val_loss: 1.0410\n",
      "Epoch 2/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 1.0790 - val_loss: 0.9673\n",
      "Epoch 3/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.9805 - val_loss: 0.9487\n",
      "Epoch 4/8\n",
      "244/244 [==============================] - 62s 253ms/step - loss: 0.9648 - val_loss: 0.9196\n",
      "Epoch 5/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8874 - val_loss: 0.9142\n",
      "Epoch 6/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8540 - val_loss: 0.9032\n",
      "Epoch 7/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8446 - val_loss: 0.8976\n",
      "Epoch 8/8\n",
      "244/244 [==============================] - 61s 251ms/step - loss: 0.8460 - val_loss: 0.8940\n"
     ]
    }
   ],
   "source": [
    "distil_hyper_model = Musk_Model()\n",
    "optimized_distil_model = distil_hyper_model.build(best_d_hp)\n",
    "optimized_distil_hist = distil_hyper_model.fit(best_d_hp,optimized_distil_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Beide Modelle erreichen letztendlich einen √§hnlichen Validation loss, dies sagt aber wenig √ºber die allgemeine Qualit√§t des Modells aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#optimized_distil_model.save_pretrained('./MUSK_DISTIL_GPT_OPTIMIZED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelle laden und Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Modelle k√∂nnen nun geladen werden und Ergebnisse produziert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_GPT_OPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_DISTIL_GPT_UNOPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_GPT_OPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./MUSK_DISTIL_GPT_OPTIMIZED.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_GPT_OPTIMIZED\")\n",
    "distil_model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_DISTIL_GPT_UNOPTIMIZED\")\n",
    "optimized_model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_GPT_OPTIMIZED\")\n",
    "optimized_distil_model = TFGPT2LMHeadModel.from_pretrained(\"./MUSK_DISTIL_GPT_OPTIMIZED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<|elontext|>\"\n",
    "default_gen = pipeline(\"text-generation\", model='gpt2')\n",
    "gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "distil_gen= pipeline('text-generation', model=distil_model, tokenizer=distil_tokenizer)\n",
    "opt_gen = pipeline('text-generation', model=optimized_model, tokenizer=tokenizer)\n",
    "opt_distil_gen = pipeline('text-generation', model=optimized_distil_model, tokenizer=distil_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modell Evaluierung\n",
    "Mit den zuvor festgelegt Prompt l√§sst sich nun Text generieren. Die Texte von GPT-2 sind zwar manchmal etwas verwirrend und ergeben inhaltlich keinen besonderen Sinn, sind aber grammatikalisch mei√üt korrekt und passen auch zu Elon Musks sonstigen Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|>\\n\\n<|b| | | a| |.\\n\\n:a b|\\n\\n.:c\\n\\n.||.\\n\\n|:m b|\\n\\n.|c\\n\\n'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default model\n",
    "default_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#default model mit tweet prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|>@jones3 @Gatorade No problem'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainiertes modell\n",
    "gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#trainiertes modell mit tweet prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|>@IDGAA That would be worth a lot of money.'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainiertes modell mit hyperparameter tuning\n",
    "opt_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Distil-GPT-2 Modell ist im Gegensatz dazu eher unbrauchbar. Die Texte ergeben keinen Sinn und haben keinen Zusammenhang. Das zeigt sich vor allem auch darin, dass die Texte grammatikalische starke Schw√§chen haben, was bei GPT2 nicht der Fall ist.\n",
    " Dieser qualitative Unterschied best√§tigt, dass der Loss kein besonders guter Indikator f√ºr die Qualit√§t des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<|elontext|> is a personal injury, and is a with a non-cabin in the trunk, and is a one-piece container.'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainiertes distilgpt2 modell mit hyperparamerter tuning\n",
    "distil_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das wird mit dem optimierten Modell ein wenig besser, allerdings gibt es auch hier keinen wirklichen Zusammenhang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"<|elontext|>First time making a Model 3.0. Autopilot is great. Hopefully by then we're all fine.\"}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainiertes distilgpt2 modell mit hyperparamerter tuning mit tweet prompt\n",
    "opt_distil_gen(BOS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stattdessen ist eine Evaluierung interessant, in der getestet wird, ob eine Gruppe aus Studierenden der Wirtschaftsinformatik die generierten Tweets von den echten Tweets unterscheiden k√∂nnen.\n",
    "F√ºr diese Evaluierung wurden zuf√§llig Paare aus echten Tweets und und falschen Tweets erstellt. Den Studierenden wurde der Auftrag gegeben, den echten Tweet von beiden zu bestimmen und daf√ºr auf einer Website abzustimmen.  Die Ergebnisse wurden in einer Datenbank gespeichert. Das genutzte Modell ist daf√ºr das erste GPT-2 Modell ohne Hyperparameter Tuning, weil dieses zu dem Zeitpunk noch nicht fertig war."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Einige Beispielpaare sind:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generierter Tweet \"The only way to reach me is to tweet @barned_slaming ‚Äú@chris_nho\"\n",
    "Echter Tweet: \"Which leads me to my next subject of gun control ... just kidding\"\n",
    "\n",
    "Generierter Tweet: \"Ô∏è Thanks for a great AMA!\",\"real\":\n",
    "Echter Tweet: \"1st firing of Falcon 9-R advanced prototype rocket. Over 1M lbs thrust, enough to lift skyscraper  http://t.co/AUCsWTw77E\"\n",
    "\n",
    "Generierter Tweet: \"I'd love to make a nice big rock on ice! Maybe some great ice cream!\"\n",
    "Echter Tweet:\"@MaxMBerger The collective wisdom of the market is usually (not always) better than the smartest govt regulator.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bei der Abstimmung konnte GPT-2 zwar in weniger F√§llen t√§uschen, dies ist aber zu erwarten, weil GPT-2 nat√ºrlich kein echter Mensch ist sondern noch immer ein Sprachmodell, das nur Sprache aber keine Inhalte versteht. Trotzdem ist die Anzahl der als falsch als echt benannten Tweets betrachtlich und Zeigt auch, dass es nicht unm√∂glich ist Menschen zu t√§uschen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Auswahl eines Modells f√ºr eine Evaluierung mit Testsubjekten\n",
    "Mit einer Gruppe Studierender soll evaluiert werden ob es mit dem Modell m√∂glich ist tweets zu generieren, die von echten Tweets nicht zu unterscheiden sind, daf√ºr soll eines der Modelle ausgew√§hlt werden.\n",
    "Weil zum Zeitpunkt des Test noch die Hyperparameter Optimierung lief, wurde das erste Modell verwendet. Dieses ist allerdings asugereift genug, um Tweets zu generieren.\n",
    "Die Gruppe Studierender √∂ffnet eine Website, auf der immer jeweils 2 Tweets pr√§sentiert werden. Die Studierenden sollen ausw√§hlen, von welchem beider Tweets sie glauben, dass er echt. Es existiert die M√∂glichkeit, dass die Tweets auch live generiert werden. Das genutzte Modell generiert allerdings gelegntlich Tweets die leer sind oder vollst√§ndig sinnlos sind. Diese automatisch herauszufiltern w√§re ein gro√üer Aufwand gewesen. Aus diesem Grund werden f√ºr das Experiment Tweets vorher generiert und auf 65 Tweets gek√ºrzt, die syntaktisch Sinn ergeben. Diese wurden dann einem echten Tweet zugeordnert und als Paar in der Datenbank gespeichert, damit sie miteinander vergleichbar sind.\n",
    "\n",
    "Insgesamt wurde 78 Mal geraten, es gab also auch Tweets, die doppelt verwendet wurden. Dabei wurde 34 Mal der Falsche und 44 Mal der richtige Tweet ausgew√§hlt. Ein optimales Ergebnis w√§re 39 zu 39 gewesen\n",
    "\n",
    "![Statistik Raten](experiment.png)\n",
    "\n",
    "\n",
    "Dieses Ergebnis l√§sst sich aus zwei Perspektiven betrachten. Aus der Sicht, dass es sich um ein Modell handelt dass menschliche Sprache imitieren soll, sind die Ergebnisse relativ gut, weil es sich dabei um eine komplizierte Aufgabe handelt. Aus der Sicht, dass den 'Probanden' aber nur ein kurzer Text gegeben wird, anhand dessen die Echtheit allgemein schlecht zu unterscheiden ist, w√§re ein Ergebniss n√§her am Optimimum w√ºnschenswert gewesen.\n",
    "\n",
    "Einige Beispiele f√ºr generierte Tweets, die f√ºr echte Tweets gehalten wurden:\n",
    "\n",
    "Echt:\"My first prediction of 2012 has come true: ouch, my head hurts.\n",
    "\n",
    "Falsch: \" @JLobuchan @Yahoo! Will do a live demo at the Air Force Museum tonight at 3pm, where all 50 astronauts will have the opportunity to speak. Thanks to everyone!\"\n",
    "\n",
    "\n",
    "\n",
    "Echt:\"No kidding\"\n",
    "\n",
    "Falsch:\"I'm a proud Canadian proud of the incredible work of @Yahoo! I hope you guys can find a cure for cancer.  link\"\n",
    "\n",
    "\n",
    "\n",
    "Echt: \"My @SpaceX team is not working for  link link\"\n",
    "\n",
    "Falsch: \"Tesla articles 30 mins apart: \"This Stock is Screaming Buy\"  link and \"This Stock Could Get DESTROYED\"  link\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fazit und Ausblick\n",
    "In dieser Arbeit lies sich zeigen, dass State-of-the-Art Machine Learning Modelle dazu genutzt werden k√∂nnen kurze Texte zu generieren, mit denen sich Menschen in ein paar F√§llen √ºberzeugen lassen sie seien echt. Das zeigt auch, dass kurze Texte mit wenige gro√üem Zusammenhang sehr einfach zu generieren sind\n",
    " Allerdings lassen sich noch viele Verbeserung auf dieses Modell anwenden. Es existieren noch viele andere Sprache-Modelle, die nicht verglichen wurden. Zudem gibt es verschiedene Arten, den Trainings-Datensatz zu struktuieren, was auch Einfluss auf das sp√§tere Modell hat. Ein weiteres interessantes Experiment ist die Generierung von Antworten auf andere Tweets anhand bisheriger Antworten. Ein interessantes Experiment w√§re es, mit dem Modell einen Bot zu entwickeln, der einen Twitter-Account als Elon Musk betreibt. Dies ist auch der einzige tats√§chliche Use-Case, der f√ºr diese Art von Modell vorstellbar ist. Generell ist das weniger als ein sinnvolles Projekt zu sehen, sondern als eine Art Benchmark, in dem zu sehen ist, was mit heutigen Modell m√∂glich ist. In diesem Fal hat sich gezeigt, dass Sprachmodelle zu sehr viel f√§hig sind, weshalb es viele Einsatzfelder f√ºr sie gibt."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b757419f8e9653efa3b1d0ab3e43e629cdfff8f48cf8c1e8bcae685186face11"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}